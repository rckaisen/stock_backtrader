{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiLVPPrrYL1j"
      },
      "outputs": [],
      "source": [
        "# Detect candlesticks patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfqXkm6-ch8H"
      },
      "outputs": [],
      "source": [
        "# download TA-Lib\n",
        "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24p_-QS8cz7S",
        "outputId": "2f805489-9fdd-4e05-e0fd-eb8797ba7d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data  ta-lib-0.4.0-src.tar.gz\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_jrGxRWc1Fg"
      },
      "outputs": [],
      "source": [
        "!tar xvzf ta-lib-0.4.0-src.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "427zDmhmc8C2",
        "outputId": "385ab8f9-ed0c-4068-b913-5e4b90fbf9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data  ta-lib  ta-lib-0.4.0-src.tar.gz\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvYfuPBYc-bO"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LcO9iuJdEB1"
      },
      "outputs": [],
      "source": [
        "os.chdir('ta-lib') # Can't use !cd in co-lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBz8MAgydHAR"
      },
      "outputs": [],
      "source": [
        "!./configure --prefix=/usr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzBhxdw9dI-z"
      },
      "outputs": [],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sntr627DdK5N"
      },
      "outputs": [],
      "source": [
        "!make install\n",
        "# wait ~ 30s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTWgTeaxdP7Y"
      },
      "outputs": [],
      "source": [
        "os.chdir('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuyY-nYadSmh",
        "outputId": "755e1e3a-9b1c-427a-e70e-0b9967b9aab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data  ta-lib  ta-lib-0.4.0-src.tar.gz\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf15I1GYYL1r"
      },
      "outputs": [],
      "source": [
        "!pip install TA-Lib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Capture candlestick patterns from stock price data**"
      ],
      "metadata": {
        "id": "pz0POirinZ55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q66JTyGZYL1s",
        "outputId": "be66de74-4696-4637-99cf-453209024e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-4ddc050ab014>:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  from pandas import datetime\n"
          ]
        }
      ],
      "source": [
        "# Main program\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from pandas import concat\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import talib\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gS-K35sNkMqK"
      },
      "outputs": [],
      "source": [
        "# parsing date function\n",
        "def parser(x):\n",
        "    return datetime.strptime(x,'%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZHBWld-VkMqK"
      },
      "outputs": [],
      "source": [
        "# read csv file using specified parsing function and index column is the first column (index=0)\n",
        "dataset = read_csv('HSI.csv',header=0,parse_dates=[0],date_parser=parser,index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KAU474hmkMqK"
      },
      "outputs": [],
      "source": [
        "# remove NaN values, drop 'Adj Close' column\n",
        "dataset = dataset.dropna().drop(['Adj Close'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df8otj1UkMqK",
        "outputId": "0de1d8a3-5ab9-49e2-ee7c-178b6bf5f2c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Open         High          Low        Close  Volume\n",
            "Date                                                                  \n",
            "1986-12-31  2568.300049  2568.300049  2568.300049  2568.300049     0.0\n",
            "1987-01-02  2540.100098  2540.100098  2540.100098  2540.100098     0.0\n",
            "1987-01-05  2552.399902  2552.399902  2552.399902  2552.399902     0.0\n",
            "1987-01-06  2583.899902  2583.899902  2583.899902  2583.899902     0.0\n",
            "1987-01-07  2607.100098  2607.100098  2607.100098  2607.100098     0.0\n",
            "1987-01-08  2603.300049  2603.300049  2603.300049  2603.300049     0.0\n",
            "1987-01-09  2561.699951  2561.699951  2561.699951  2561.699951     0.0\n",
            "1987-01-12  2614.899902  2614.899902  2614.899902  2614.899902     0.0\n",
            "1987-01-13  2590.800049  2590.800049  2590.800049  2590.800049     0.0\n",
            "1987-01-14  2578.199951  2578.199951  2578.199951  2578.199951     0.0\n",
            "Dataset shape:  (7936, 5)\n"
          ]
        }
      ],
      "source": [
        "# preview the dataset\n",
        "print(dataset.head(n=10))\n",
        "print(\"Dataset shape: \", dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "E6TcqgojkMqK"
      },
      "outputs": [],
      "source": [
        "# set arrays of open, high, low and close prices\n",
        "pOpen = dataset['Open'].values\n",
        "pHigh = dataset['High'].values\n",
        "pLow = dataset['Low'].values\n",
        "pClose = dataset['Close'].values\n",
        "volume = dataset['Volume'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LGIfxJElkMqL"
      },
      "outputs": [],
      "source": [
        "# make a copy of the dataset\n",
        "df = dataset.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yzr-W-tTkMqL"
      },
      "outputs": [],
      "source": [
        "# Two Crows (-100 denotes bearish)\n",
        "patternName = 'CDL2CROWS'\n",
        "output = talib.CDL2CROWS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three Black Crows (-100 denotes bearish)\n",
        "patternName = 'CDL3BLACKCROWS'\n",
        "output = talib.CDL3BLACKCROWS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three Inside Up/Down (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDL3INSIDE'\n",
        "output = talib.CDL3INSIDE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three-Line Strike (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDL3LINESTRIKE'\n",
        "output = talib.CDL3LINESTRIKE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three Outside Up/Down (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDL3OUTSIDE'\n",
        "output = talib.CDL3OUTSIDE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eA7Oji7LkMqL"
      },
      "outputs": [],
      "source": [
        "# Three Stars In The South (+100 denotes bullish)\n",
        "patternName = 'CDL3STARSINSOUTH'\n",
        "output = talib.CDL3STARSINSOUTH(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three Advancing White Soldiers (+100 denotes bullish)\n",
        "patternName = 'CDL3WHITESOLDIERS'\n",
        "output = talib.CDL3WHITESOLDIERS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Abandoned Baby (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLABANDONEDBABY'\n",
        "output = talib.CDLABANDONEDBABY(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Advance Block (-100 denotes bearish)\n",
        "patternName = 'CDLADVANCEBLOCK'\n",
        "output = talib.CDLADVANCEBLOCK(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Belt-hold (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLBELTHOLD'\n",
        "output = talib.CDLBELTHOLD(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uqsfFT0jkMqM"
      },
      "outputs": [],
      "source": [
        "# Breakaway (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLBREAKAWAY'\n",
        "output = talib.CDLBREAKAWAY(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Closing Marubozu (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLCLOSINGMARUBOZU'\n",
        "output = talib.CDLCLOSINGMARUBOZU(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Concealing Baby Swallow (+100 denotes bullish)\n",
        "patternName = 'CDLCONCEALBABYSWALL'\n",
        "output = talib.CDLCONCEALBABYSWALL(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Counterattack (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLCOUNTERATTACK'\n",
        "output = talib.CDLCOUNTERATTACK(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Dark Cloud Cover (-100 denotes bearish)\n",
        "patternName = 'CDLDARKCLOUDCOVER'\n",
        "output = talib.CDLDARKCLOUDCOVER(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_eekU4sPkMqN"
      },
      "outputs": [],
      "source": [
        "# Doji (+100 denotes bullish)\n",
        "patternName = 'CDLDOJI'\n",
        "output = talib.CDLDOJI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Doji Star (-100 denotes bearlish, +100 denotes bullish)\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][p\n",
        "patternName = 'CDLDOJISTAR'\n",
        "output = talib.CDLDOJISTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Dragonfly Doji (+100 denotes bullish)\n",
        "patternName = 'CDLDRAGONFLYDOJI'\n",
        "output = talib.CDLDRAGONFLYDOJI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Engulfing Pattern (-100 denotes bearlish, +100 denotes bullish)\n",
        "patternName = 'CDLENGULFING'\n",
        "output = talib.CDLENGULFING(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Evening Doji Star (-100 denotes bearlish)\n",
        "patternName = 'CDLEVENINGDOJISTAR'\n",
        "output = talib.CDLEVENINGDOJISTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vuAj5tCYkMqN"
      },
      "outputs": [],
      "source": [
        "# Evening Star (-100 denotes bearlish)\n",
        "patternName = 'CDLEVENINGSTAR'\n",
        "output = talib.CDLEVENINGSTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Up/Down-gap side-by-side white lines (-100 denotes bearlish, +100 denotes bullish)\n",
        "patternName = 'CDLGAPSIDESIDEWHITE'\n",
        "output = talib.CDLGAPSIDESIDEWHITE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Gravestone Doji (+100 denotes bullish)\n",
        "patternName = 'CDLGRAVESTONEDOJI'\n",
        "output = talib.CDLGRAVESTONEDOJI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Hammer (+100 denotes bullish)\n",
        "patternName = 'CDLHAMMER'\n",
        "output = talib.CDLHAMMER(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Hanging Man (-100 denotes bearish)\n",
        "patternName = 'CDLHANGINGMAN'\n",
        "output = talib.CDLHANGINGMAN(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BRvoK6TbkMqO"
      },
      "outputs": [],
      "source": [
        "# Harami Pattern (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLHARAMI'\n",
        "output = talib.CDLHARAMI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Harami Cross Pattern (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLHARAMICROSS'\n",
        "output = talib.CDLHARAMICROSS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# High-Wave Candle (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLHIGHWAVE'\n",
        "output = talib.CDLHIGHWAVE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Hikkake Pattern\n",
        "patternName = 'CDLHIKKAKE'\n",
        "output = talib.CDLHIKKAKE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Modified Hikkake Pattern\n",
        "patternName = 'CDLHIKKAKEMOD'\n",
        "output = talib.CDLHIKKAKEMOD(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "D3CBMNLakMqO"
      },
      "outputs": [],
      "source": [
        "# Homing Pigeon (+100 denotes bullish)\n",
        "patternName = 'CDLHOMINGPIGEON'\n",
        "output = talib.CDLHOMINGPIGEON(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Identical Three Crows (-100 denotes bearish)\n",
        "patternName = 'CDLIDENTICAL3CROWS'\n",
        "output = talib.CDLIDENTICAL3CROWS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# In-Neck Pattern (-100 denotes bearish)\n",
        "patternName = 'CDLINNECK'\n",
        "output = talib.CDLINNECK(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Inverted Hammer (+100 denotes bullish)\n",
        "patternName = 'CDLINVERTEDHAMMER'\n",
        "output = talib.CDLINVERTEDHAMMER(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Kicking (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLKICKING'\n",
        "output = talib.CDLKICKING(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3JaioAaqkMqO"
      },
      "outputs": [],
      "source": [
        "# Kicking - bull/bear determined by the longer marubozu (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLKICKINGBYLENGTH'\n",
        "output = talib.CDLKICKINGBYLENGTH(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Ladder Bottom (+100 denotes bullish)\n",
        "patternName = 'CDLLADDERBOTTOM'\n",
        "output = talib.CDLLADDERBOTTOM(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Long Legged Doji (+100 denotes bullish)\n",
        "patternName = 'CDLLONGLEGGEDDOJI'\n",
        "output = talib.CDLLONGLEGGEDDOJI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Long Line Candle (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLLONGLINE'\n",
        "output = talib.CDLLONGLINE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Marubozu (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLMARUBOZU'\n",
        "output = talib.CDLMARUBOZU(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "RP1ayq3ikMqP"
      },
      "outputs": [],
      "source": [
        "# Matching Low (+100 denotes bullish)\n",
        "patternName = 'CDLMATCHINGLOW'\n",
        "output = talib.CDLMATCHINGLOW(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Mat Hold (+100 denotes bullish)\n",
        "patternName = 'CDLMATHOLD'\n",
        "output = talib.CDLMATHOLD(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Morning Doji Star (+100 denotes bullish)\n",
        "patternName = 'CDLMORNINGDOJISTAR'\n",
        "output = talib.CDLMORNINGDOJISTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Morning Star (+100 denotes bullish)\n",
        "patternName = 'CDLMORNINGSTAR'\n",
        "output = talib.CDLMORNINGSTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# On-Neck Pattern (-100 denotes bearish)\n",
        "patternName = 'CDLONNECK'\n",
        "output = talib.CDLONNECK(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SFQNYb7EkMqP"
      },
      "outputs": [],
      "source": [
        "# Piercing Pattern (+100 denotes bullish)\n",
        "patternName = 'CDLPIERCING'\n",
        "output = talib.CDLPIERCING(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Rickshaw Man (+100 denotes bullish)\n",
        "patternName = 'CDLRICKSHAWMAN'\n",
        "output = talib.CDLRICKSHAWMAN(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Rising/Falling Three Methods (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLRISEFALL3METHODS'\n",
        "output = talib.CDLRISEFALL3METHODS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Separating Lines (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLSEPARATINGLINES'\n",
        "output = talib.CDLSEPARATINGLINES(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Shooting Star (-100 denotes bearish)\n",
        "patternName = 'CDLSHOOTINGSTAR'\n",
        "output = talib.CDLSHOOTINGSTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "w1rRhOjOkMqP"
      },
      "outputs": [],
      "source": [
        "# Short Line Candle (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLSHORTLINE'\n",
        "output = talib.CDLSHORTLINE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Spinning Top (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLSPINNINGTOP'\n",
        "output = talib.CDLSPINNINGTOP(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Stalled Pattern (-100 denotes bearish)\n",
        "patternName = 'CDLSTALLEDPATTERN'\n",
        "output = talib.CDLSTALLEDPATTERN(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Stick Sandwich (-100 denotes bearish)\n",
        "patternName = 'CDLSTICKSANDWICH'\n",
        "output = talib.CDLSTICKSANDWICH(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Takuri (Dragonfly Doji with very long lower shadow) (+100 denotes bullish)\n",
        "patternName = 'CDLTAKURI'\n",
        "output = talib.CDLTAKURI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8Wx7cjKckMqP"
      },
      "outputs": [],
      "source": [
        "# Tasuki Gap (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLTASUKIGAP'\n",
        "output = talib.CDLTASUKIGAP(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Thrusting Pattern (-100 denotes bearish)\n",
        "patternName = 'CDLTHRUSTING'\n",
        "output = talib.CDLTHRUSTING(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Tristar Pattern (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLTRISTAR'\n",
        "output = talib.CDLTRISTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Unique 3 River (+100 denotes bullish)\n",
        "patternName = 'CDLUNIQUE3RIVER'\n",
        "output = talib.CDLUNIQUE3RIVER(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Upside Gap Two Crows (-100 denotes bearish)\n",
        "patternName = 'CDLUPSIDEGAP2CROWS'\n",
        "output = talib.CDLUPSIDEGAP2CROWS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Upside/Downside Gap Three Methods (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLXSIDEGAP3METHODS'\n",
        "output = talib.CDLXSIDEGAP3METHODS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7IkmaPQIkMqQ"
      },
      "outputs": [],
      "source": [
        "df.to_csv('data/candlesticks_patterns.csv')\n",
        "#sys.exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing features**"
      ],
      "metadata": {
        "id": "x-zcmnConP5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# Preprocessing features and output to file\n",
        "#\n",
        "# Output file: preprocessed_features.csv\n",
        "############################################\n",
        "\n",
        "####\n",
        "# open\n",
        "# close\n",
        "# low\n",
        "# high\n",
        "# volume\n",
        "# RSI(14)\n",
        "# MACD(12,26), EMA(9), Divergence\n",
        "# SMA(10), SMA(20), SMA(50), SMA(100), SMA(200)\n",
        "# OBV\n",
        "# ROC\n",
        "####\n",
        "\n",
        "\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from pandas import concat\n",
        "from pandas import DataFrame\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import talib\n",
        "import sys\n",
        "import six\n",
        "import pywt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9td0Ir6nyby",
        "outputId": "d881634a-376c-41eb-92bb-05736eb7c791"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-e783e2964047>:22: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  from pandas import datetime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parsing date\n",
        "def parser(x):\n",
        "  return datetime.strptime(x,'%Y-%m-%d')"
      ],
      "metadata": {
        "id": "F_q25CSZn6v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class labeling for positive and negative number\n",
        "def classlabeling(diff):\n",
        "  if (diff >= 0):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "0EV22aQPoA1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate percentage change\n",
        "pct_chg_fxn = lambda x: x.pct_change()"
      ],
      "metadata": {
        "id": "S3Ic38F8oDiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# Candlesticks Patterns\n",
        "########################\n",
        "def getCandleSticks(candlesticks):\n",
        "  #print(candlesticks.shape)\n",
        "\n",
        "  start = 5\n",
        "  end = 66\n",
        "  candles = candlesticks.iloc[:,start:end]\n",
        "  #print(candles.shape)\n",
        "\n",
        "  candles = candles.clip(-100,100)\n",
        "  candles = candles.replace(to_replace=100, value=1)\n",
        "  candles = candles.replace(to_replace=-100, value=-1)\n",
        "  candles = candles.sum(axis=1)\n",
        "  dataset['candlesticks'] = candles.clip(-3,3)\n",
        "  dataset['candlesticks'] = dataset['candlesticks'].shift(1).fillna(0).astype('int')\n",
        "  #print(dataset.head(30))"
      ],
      "metadata": {
        "id": "nBTAhQWToFnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############\n",
        "# RSI Change\n",
        "##############\n",
        "def categorizeRSI(rsi):\n",
        "  if (rsi >= 70):\n",
        "    return 2\n",
        "  elif (rsi <= 30):\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "metadata": {
        "id": "d17x1PySoJLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RSI_1hot(rsi):\n",
        "  encoder = OneHotEncoder()\n",
        "  lb = LabelBinarizer()\n",
        "  df_cat_1hot = encoder.fit_transform(rsi)\n",
        "  print(\"1hot: \", df_cat_1hot.toarray())\n",
        "  x = lb.fit_transform(np.array(df_cat_1hot.toarray()))\n",
        "  print(\"lb: \", x)\n",
        "  y = lb.inverse_transform(x)\n",
        "  print(\"lb: \", y)\n",
        "  #print(\"check: \", encoder.transform([[0,1], [1,2], [2,1], [1,0], [0,2], [2,0], [0,0], [1,1], [2,2]]).toarray())\n",
        "  #return df_cat_1hot"
      ],
      "metadata": {
        "id": "DdnGlm68oRli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(v, cat):\n",
        "  if (v == True):\n",
        "    return cat\n",
        "  elif (v == False):\n",
        "    return 0"
      ],
      "metadata": {
        "id": "GKBTZzjloTr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relabel(val):\n",
        "  if (val == 1):\n",
        "    #return \"noChange_below30\"\n",
        "    return 1\n",
        "  elif (val == 2):\n",
        "    #return \"noChange_btw30and70\"\n",
        "    return 2\n",
        "  elif (val == 3):\n",
        "    #return \"noChange_above70\"\n",
        "    return 3\n",
        "  elif (val == 4):\n",
        "    #return \"below30_to_btw30and70\"\n",
        "    return 4\n",
        "  elif (val == 5):\n",
        "    #return \"btw30and70_to_above70\"\n",
        "    return 5\n",
        "  elif (val == 6):\n",
        "    #return \"above70_to_btw30and70\"\n",
        "    return 6\n",
        "  elif (val == 7):\n",
        "    #return \"btw30and70_to_below30\"\n",
        "    return 7\n",
        "  elif (val == 8):\n",
        "    #return \"below30_to_above70\"\n",
        "    return 8\n",
        "  elif (val == 9):\n",
        "    #return \"above70_to_below30\"\n",
        "    return 9"
      ],
      "metadata": {
        "id": "OAisTtemoVz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RSI_patterns(a, b):\n",
        "  # prev=0, curr=0 (both previous RSI and current RSI are below 30)\n",
        "  pattern1 = np.logical_and(a==0, b==0)\n",
        "  pattern1 = pattern1.apply(lambda v: convert(v, 1))\n",
        "  # prev=1, curr=1 (both previous RSI and current RSI are between 30 and 70)\n",
        "  pattern2 = np.logical_and(a==1, b==1)\n",
        "  pattern2 = pattern2.apply(lambda v: convert(v, 2))\n",
        "  # prev=2, curr=2 (both previous RSI and current RSI are above 70)\n",
        "  pattern3 = np.logical_and(a==2, b==2)\n",
        "  pattern3 = pattern3.apply(lambda v: convert(v, 3))\n",
        "  # prev=0, curr=1 (previous RSI below 30 goes up to current RSI 30~70 range)\n",
        "  pattern4 = np.logical_and(a==0, b==1)\n",
        "  pattern4 = pattern4.apply(lambda v: convert(v, 4))\n",
        "  # prev=1, curr=2 (previous RSI 30~70 range goes up to current RSI above 70)\n",
        "  pattern5 = np.logical_and(a==1, b==2)\n",
        "  pattern5 = pattern5.apply(lambda v: convert(v, 5))\n",
        "  # prev=2, curr=1 (previous RSI above 70 goes down to current RSI 30~70 range)\n",
        "  pattern6 = np.logical_and(a==2, b==1)\n",
        "  pattern6 = pattern6.apply(lambda v: convert(v, 6))\n",
        "  # prev=1, curr=0 (previous RSI 30~70 range goes down to current RSI below 30)\n",
        "  pattern7 = np.logical_and(a==1, b==0)\n",
        "  pattern7 = pattern7.apply(lambda v: convert(v, 7))\n",
        "  # prev=0, curr=2 (previous RSI below 30 goes up to current RSI above 70)\n",
        "  pattern8 = np.logical_and(a==0, b==2)\n",
        "  pattern8 = pattern8.apply(lambda v: convert(v, 8))\n",
        "  # prev=2, curr=0 (previous RSI above 70 goes down to current RSI below 30)\n",
        "  pattern9 = np.logical_and(a==2, b==0)\n",
        "  pattern9 = pattern9.apply(lambda v: convert(v, 9))\n",
        "  # add all columns element-wise\n",
        "  dataset['RSI_5day_vs_prevday'] = np.add(np.add(np.add(np.add(np.add(np.add(np.add(np.add(pattern1, pattern2), pattern3), pattern4), pattern5), pattern6), pattern7), pattern8), pattern9)\n",
        "  dataset['RSI_5day_vs_prevday'] = dataset['RSI_5day_vs_prevday'].shift(-5).fillna(1).astype('int')\n",
        "  dataset['RSI_5day_vs_prevday'] = dataset['RSI_5day_vs_prevday'].apply(lambda v: relabel(v))\n",
        "  #return pattern1, pattern2, pattern3, pattern4, pattern5, pattern6, pattern7, pattern8, pattern9\n",
        "  #return output\n"
      ],
      "metadata": {
        "id": "ljAHUu4boYqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getRSIChange(dataset):\n",
        "  # Compute RSI of close price\n",
        "  rsi = talib.RSI(dataset[\"Close\"].values, timeperiod=14)\n",
        "  #print(rsi.shape)\n",
        "\n",
        "  # Add columns of RSI and RSI Change dataset\n",
        "  # Use diff() to calculate difference\n",
        "  # Use pct_change() to calculate pct_change() (not used in current setting)\n",
        "  # Use categorizeRSI() to classify RSI value level (not used in current setting)\n",
        "  dataset['RSI'] = rsi\n",
        "  dataset['RSI_PREV'] = dataset['RSI'].shift(1).fillna(0).astype('int')\n",
        "  dataset['RSI_PREV_CAT'] = dataset['RSI_PREV'].apply(lambda d: categorizeRSI(d))\n",
        "  #dataset['RSI_CAT'] = dataset['RSI'].apply(lambda d: categorizeRSI(d))\n",
        "  #dataset['RSI_CAT_PREV'] = dataset['RSI_CAT'].shift(1).fillna(0).astype('int')\n",
        "  #dataset['RSI_CAT_NEXT'] = dataset['RSI_CAT'].shift(-1).fillna(0).astype('int')\n",
        "  #dataset['RSI_CHG'] = dataset['RSI'].diff()\n",
        "  #dataset['RSI_CHG_CAT'] = dataset['RSI_CHG'].apply(lambda d: classlabeling(d))\n",
        "  #dataset['RSI_CHG_ROC'] = dataset['RSI_CHG'].pct_change()\n",
        "  dataset['RSI_AVG_5DAYS'] = talib.SMA(dataset['RSI_PREV'], timeperiod=5).fillna(0).astype('int').shift(-5)\n",
        "  dataset['RSI_AVG_5DAYS_CAT'] = dataset['RSI_AVG_5DAYS'].apply(lambda d: categorizeRSI(d))\n",
        "  # compare RSI_AVG_5DAYS_CAT and RSI_CAT_PREV\n",
        "  dataset = dataset.dropna()\n",
        "\n",
        "\n",
        "  # df_encoded, df_categories = dataset[['RSI_CAT_PREV','RSI_CAT']].factorize()\n",
        "  # print(\"2: \", df_encoded[:])\n",
        "  # print(\"3: \", df_categories[:])\n",
        "  #RSI_1hot(dataset[['RSI_CAT_PREV','RSI_CAT']])\n",
        "  #dataset['NoChange_below30'], dataset['NoChange_normal'], dataset['NoChange_above70'], dataset['below30_to_normal'], dataset['normal_to_above70'], dataset['above70_to_normal'], dataset['normal_to_below30'], dataset['below30_to_above70'], dataset['above70_to_below30'] = check(dataset['RSI_AVG_5DAYS_CAT'], dataset['RSI_PREV_CAT'])\n",
        "  #dataset['RSI_5day_vs_prevday'] = RSI_patterns(dataset['RSI_AVG_5DAYS_CAT'], dataset['RSI_PREV_CAT'])\n",
        "  RSI_patterns(dataset['RSI_AVG_5DAYS_CAT'], dataset['RSI_PREV_CAT'])\n",
        "  # skip first 5 rows because of RSI average 5 days\n",
        "  #print(dataset[5:])\n",
        "\n",
        "  #plt.hist(dataset['RSI'], bins = 30)\n",
        "  #plt.xlabel(\"Number\")\n",
        "  #plt.ylabel(\"Frequency\")\n",
        "  #plt.show()"
      ],
      "metadata": {
        "id": "xHH-AAYGocR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# Close Price Change\n",
        "#####################\n",
        "def getCloseChange(dataset):\n",
        "  dataset['CLOSE_CHG'] = dataset['Close'].diff()\n",
        "  dataset['CLOSE_CHG_CAT'] = dataset['CLOSE_CHG'].shift(1).apply(lambda d: classlabeling(d))\n",
        "  #dataset['Close_LOG'] = np.log(dataset['Close'])\n",
        "  #dataset = dataset.dropna()\n",
        "  #print(dataset.head(30))"
      ],
      "metadata": {
        "id": "9uEtGYkWogz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "# feature: Rate of change of close price\n",
        "#########################################\n",
        "def roc_slope(df, days):\n",
        "  sma = talib.SMA(df, timeperiod=days)\n",
        "  rocOfValue = talib.ROCP(sma, timeperiod=days)\n",
        "  rocOfValueChange = talib.ROCP(rocOfValue, timeperiod=days)\n",
        "  rocOfValueChangeCat = rocOfValueChange.apply(lambda d: 1 if d>=0 else -1)\n",
        "  return rocOfValueChange, rocOfValueChangeCat\n",
        "\n",
        "def getRocOFCloseChange(dataset):\n",
        "  # Calculate ROC of value change of SMA of 2 days\n",
        "  dataset['rocOFCloseChange'], dataset['rocOFCloseChangeCat'] = roc_slope(dataset['Close'], 2)\n",
        "  #dataset = dataset.dropna()\n",
        "  #print(dataset.head(30))"
      ],
      "metadata": {
        "id": "Tsu_p5szolIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################\n",
        "# feature: SMA\n",
        "################\n",
        "def smaDiff(d1, d2, l1, l2):\n",
        "  diff1 = (d1 - d2).apply(lambda d: 1 if  d>=0 else -1)  # previous day\n",
        "  dataset['diff1'] = diff1\n",
        "  diff2 = diff1.shift(1).apply(lambda d: 1 if  d>=0 else -1)  # previous two days\n",
        "  dataset['diff2'] = diff2\n",
        "\n",
        "  dataset['test1'] = ((diff1 == 1) & (diff2 == 1)).apply(lambda x: 1 if x==True else 0) # sma5 above sma14\n",
        "  dataset['test2'] = ((diff1 == 1) & (diff2 == -1)).apply(lambda x: 2 if x==True else 0) # sma5 cross below sma14\n",
        "  dataset['test3'] = ((diff1 == -1) & (diff2 == 1)).apply(lambda x: 3 if x==True else 0) # sma5 cross above sma14\n",
        "  dataset['test4'] = ((diff1 == -1) & (diff2 == -1)).apply(lambda x: 4 if x==True else 0) # sma5 below sma14\n",
        "  #dataset['smaDiff_5_14'] = (np.add(np.add(np.add(dataset['test1'], dataset['test2']), dataset['test3']), dataset['test4'])).apply(lambda x: 'sma5_above_sma14' if x==1 else 'sma_cross_below_sma14' if x==2 else 'sma5_cross_above_sma14' if x==3 else 'sma5_below_sma14')\n",
        "  dataset['smaDiff_5_14'] = (np.add(np.add(np.add(dataset['test1'], dataset['test2']), dataset['test3']), dataset['test4']))\n",
        "\n",
        "  #result = (diff1 - diff2).apply(lambda d: l1+\"_cross_above_\"+l2 if d==-2 else (l1+\"_cross_below_\"+l2 if d==2 else \"sma_normal\"))\n",
        "  #print(dataset.head(50))\n",
        "  #return result"
      ],
      "metadata": {
        "id": "vLD4Bn6-ol-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSMA(dataset):\n",
        "  dataset['sma5'] = talib.SMA(dataset.Close, timeperiod=5)\n",
        "  dataset['sma14'] = talib.SMA(dataset.Close, timeperiod=14)\n",
        "  #dataset['sma50'] = talib.SMA(dataset.Close, timeperiod=50)\n",
        "  #dataset['sma200'] = talib.SMA(dataset.Close, timeperiod=200)\n",
        "  #dataset.dropna(inplace=True)\n",
        "  smaDiff(dataset['sma5'], dataset['sma14'], 'sma5', 'sma14')\n",
        "  #dataset['smaDiff_5_14'] = smaDiff(dataset['sma5'], dataset['sma14'], 'sma5', 'sma14')\n",
        "  #dataset['smaDiff_5_50'] = smaDiff(dataset['sma5'], dataset['sma50'], 'sma5', 'sma50')\n",
        "  #dataset['smaDiff_5_200'] = smaDiff(dataset['sma5'], dataset['sma200'], 'sma5', 'sma200')\n",
        "  #dataset['smaDiff_14_50'] = smaDiff(dataset['sma14'], dataset['sma50'], 'sma14', 'sma50')\n",
        "  #dataset['smaDiff_14_200'] = smaDiff(dataset['sma14'], dataset['sma200'], 'sma14', 'sma200')\n",
        "  #dataset['smaDiff_50_200'] = smaDiff(dataset['sma50'], dataset['sma200'], 'sma50', 'sma200')\n",
        "  #print(dataset.head(30))\n"
      ],
      "metadata": {
        "id": "VpEIQgmOooWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# feature: Volume\n",
        "##################\n",
        "def getVolumnChange(dataset):\n",
        "  dataset['OBV'] = talib.OBV(dataset[\"Close\"], dataset[\"Volume\"])\n",
        "  dataset['Volume_CHG'] = dataset['Volume'].shift(1).pct_change()\n",
        "  dataset['prev1_volume'] = dataset['Volume'].shift(1)\n",
        "  dataset['prev2_volume'] = dataset['Volume'].shift(2)\n",
        "  dataset['prev3_volume'] = dataset['Volume'].shift(3)\n",
        "  dataset['sma5_volume'] = talib.SMA(dataset.prev1_volume, timeperiod=5)\n",
        "\n",
        "  check_vol_uptrend(dataset['prev1_volume'], dataset['prev2_volume'], dataset['prev3_volume'], dataset['sma5_volume'])\n",
        "  check_vol_downtrend(dataset['prev1_volume'], dataset['prev2_volume'], dataset['prev3_volume'], dataset['sma5_volume'])\n",
        "  dataset.dropna(inplace=True)\n",
        "  combined_volume_trends(dataset['vol_up_trend'], dataset['vol_down_trend'])\n",
        "\n",
        "# previous 3 days volume greater than sma5_volume\n",
        "def check_vol_uptrend(d1, d2, d3, d4):\n",
        "  dataset['vol_up_trend'] = np.logical_and(np.logical_and(d1>d4, d2>d4), d3>d4)\n",
        "\n",
        "# previous 3 days volume less than sma5_volume\n",
        "def check_vol_downtrend(d1, d2, d3, d4):\n",
        "  dataset['vol_down_trend'] = np.logical_and(np.logical_and(d1<d4, d2<d4), d3<d4)\n",
        "\n",
        "def combined_volume_trends(d1, d2):\n",
        "  dataset['vol_test1'] = ((d1 == False) & (d2 == False)).apply(lambda x: 0 if x==True else 0)\n",
        "  dataset['vol_test2'] = ((d1 == True) & (d2 == False)).apply(lambda x: 1 if x==True else 0)\n",
        "  dataset['vol_test3'] = ((d1 == False) & (d2 == True)).apply(lambda x: 2 if x==True else 0)\n",
        "  dataset['vol_trend'] = (np.add(np.add(dataset['vol_test1'], dataset['vol_test2']), dataset['vol_test3'])).apply(lambda x: 'vol_normal' if x==0 else 'vol_up_trend' if x==1 else 'vol_down_trend')\n",
        "\n",
        "\n",
        "  #dataset = dataset.dropna()\n",
        "  print(dataset.head(60))\n",
        "\n",
        "  quantile_list = [0, .25, .5, .75, 1.]\n",
        "  quantiles = dataset['Volume'].quantile(quantile_list)\n",
        "  #print(\"quantiles: \", quantiles)\n",
        "\n",
        "  # fig, ax = plt.subplots()\n",
        "  # dataset['Volume'].hist(bins=30, color='#A9C5D3', edgecolor='black', grid=False)\n",
        "  # for quantile in quantiles:\n",
        "  #   qvl = plt.axvline(quantile, color='r')\n",
        "  #   ax.legend([qvl], ['Quantiles'], fontsize=10)\n",
        "  #   ax.set_title('Volumn', fontsize=12)\n",
        "  #   ax.set_xlabel('Volumn range', fontsize=12)\n",
        "  #   ax.set_ylabel('Frequency', fontsize=12)\n",
        "\n",
        "  #plt.hist(dataset['Volume'], bins = 30)\n",
        "  #plt.xlabel(\"Number\")\n",
        "  #plt.ylabel(\"Frequency\")\n",
        "  #plt.show()\n",
        "\n",
        "  quantile_labels = ['vol_low', 'vol_medium_low', 'vol_medium_high', 'vol_high']\n",
        "  dataset['volumn_quantile_range'] = pd.qcut(\n",
        "                                            dataset['Volume'],\n",
        "                                            q=quantile_list)\n",
        "  dataset['volumn_quantile_label'] = pd.qcut(\n",
        "                                            dataset['Volume'],\n",
        "                                            q=quantile_list,\n",
        "                                            labels=quantile_labels)"
      ],
      "metadata": {
        "id": "WIatM1r1oqZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# Get previous close price trend\n",
        "#################################\n",
        "def check_prevclose_uptrend(d1, d2, d3, d4):\n",
        "  dataset['prevclose_up_trend'] = np.logical_and(np.logical_and(d1>d4, d2>d4), d3>d4)\n",
        "\n",
        "# next 3 days close price greater than sma3\n",
        "def check_prevclose_downtrend(d1, d2, d3, d4):\n",
        "  dataset['prevclose_down_trend'] = np.logical_and(np.logical_and(d1<d4, d2<d4), d3<d4)\n",
        "\n",
        "def combined_prevclose_trends(d1, d2):\n",
        "  dataset['test1'] = ((d1 == False) & (d2 == False)).apply(lambda x: 0 if x==True else 0)\n",
        "  dataset['test2'] = ((d1 == True) & (d2 == False)).apply(lambda x: 1 if x==True else 0)\n",
        "  dataset['test3'] = ((d1 == False) & (d2 == True)).apply(lambda x: 2 if x==True else 0)\n",
        "  #dataset['prevclose_price_trend'] = (np.add(np.add(dataset['test1'], dataset['test2']), dataset['test3'])).apply(lambda x: 'prevclose_na' if x==0 else 'prevclose_up_trend' if x==1 else 'prevclose_down_trend')\n",
        "  dataset['prevclose_price_trend'] = (np.add(np.add(dataset['test1'], dataset['test2']), dataset['test3']))\n",
        "\n",
        "def getPrevCloseTrend(dataset):\n",
        "  dataset['prevclose_1'] = dataset.Close.shift(1)\n",
        "  dataset['prevclose_2'] = dataset.Close.shift(2)\n",
        "  dataset['prevclose_3'] = dataset.Close.shift(3)\n",
        "  dataset['prevclose_sma5'] = talib.SMA(dataset['prevclose_1'], timeperiod=5)\n",
        "  check_prevclose_uptrend(dataset['prevclose_1'], dataset['prevclose_2'], dataset['prevclose_3'], dataset['prevclose_sma5'])\n",
        "  check_prevclose_downtrend(dataset['prevclose_1'], dataset['prevclose_2'], dataset['prevclose_3'], dataset['prevclose_sma5'])\n",
        "  #dataset.dropna(inplace=True)\n",
        "  combined_prevclose_trends(dataset['prevclose_up_trend'], dataset['prevclose_down_trend'])\n",
        "  print(dataset.head(30))"
      ],
      "metadata": {
        "id": "mIXyPIvGoxgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# create outcome dataframe\n",
        "###########################\n",
        "# next 3 days close price greater than sma3\n",
        "def check_uptrend(d1, d2, d3, d4):\n",
        "  outcomes['up_trend'] = np.logical_and(np.logical_and(d1>d4, d2>d4), d3>d4)\n",
        "\n",
        "# next 3 days close price greater than sma3\n",
        "def check_downtrend(d1, d2, d3, d4):\n",
        "  outcomes['down_trend'] = np.logical_and(np.logical_and(d1<d4, d2<d4), d3<d4)\n",
        "\n",
        "# combine up_trend and down_trend, re-label for feature association\n",
        "def combined_trends(d1, d2):\n",
        "  outcomes['test1'] = ((d1 == False) & (d2 == False)).apply(lambda x: 0 if x==True else 0)\n",
        "  outcomes['test2'] = ((d1 == True) & (d2 == False)).apply(lambda x: 1 if x==True else 0)\n",
        "  outcomes['test3'] = ((d1 == False) & (d2 == True)).apply(lambda x: 2 if x==True else 0)\n",
        "  #outcomes['nextclose_price_trend'] = (np.add(np.add(outcomes['test1'], outcomes['test2']), outcomes['test3'])).apply(lambda x: 'nextclose_na' if x==0 else 'nextclose_up_trend' if x==1 else 'nextclose_down_trend')\n",
        "  outcomes['nextclose_price_trend'] = (np.add(np.add(outcomes['test1'], outcomes['test2']), outcomes['test3']))\n",
        "\n",
        "def createOutcomesDataframe(dataset):\n",
        "  # next day's opening change\n",
        "  outcomes['Close'] = dataset.Close\n",
        "  #outcomes['open_1'] = dataset.Open.shift(-1)/dataset.Close.shift(0)-1\n",
        "  # next day's closing change\n",
        "  #outcomes['close_1'] = dataset.Close.pct_change(-1)\n",
        "  #outcomes['close_1_CAT'] = dataset.Close.pct_change(-1).apply(lambda d: 1 if d>=0 else -1)\n",
        "  #outcomes['close_5'] = dataset.Close.pct_change(-5)\n",
        "  #outcomes['close_5'] = talib.ROC(dataset['Close'], timeperiod=5).shift(-5)\n",
        "  #outcomes['close_5_CAT'] = outcomes['close_5'].apply(lambda d: 'close_up_5day' if d>=0 else 'close_down_5day')\n",
        "  outcomes['close_1'] = dataset.Close.shift(-1)\n",
        "  outcomes['close_2'] = dataset.Close.shift(-2)\n",
        "  outcomes['close_3'] = dataset.Close.shift(-3)\n",
        "  outcomes['close_4'] = dataset.Close.shift(-4)\n",
        "  outcomes['close_5'] = dataset.Close.shift(-5)\n",
        "  #outcomes['sma5'] = talib.SMA(outcomes['close_5'], timeperiod=5)\n",
        "  outcomes['sma5'] = (outcomes['close_1']+outcomes['close_2']+outcomes['close_3']+outcomes['close_4']+outcomes['close_5'])/5\n",
        "  check_uptrend(outcomes['close_1'], outcomes['close_2'], outcomes['close_3'], outcomes['sma5'])\n",
        "  check_downtrend(outcomes['close_1'], outcomes['close_2'], outcomes['close_3'], outcomes['sma5'])\n",
        "  outcomes.dropna(inplace=True)\n",
        "  combined_trends(outcomes['up_trend'], outcomes['down_trend'])\n",
        "  #print(outcomes.isnull().values.any())\n",
        "  #print(outcomes.tail(15))\n",
        "  print(outcomes.tail(30))\n",
        "\n",
        "def showHistogram(data):\n",
        "  # show histogram of next day's closing change categories\n",
        "  # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
        "  # n, bins, patches = plt.hist(x=data, bins='auto', color='#0504aa', alpha=0.7, rwidth=0.85)\n",
        "  # plt.grid(axis='y', alpha=0.75)\n",
        "  # plt.xlabel('Value Range')\n",
        "  # plt.ylabel('Frequency')\n",
        "  # plt.title(\"Next day's closing change categories\")\n",
        "  # plt.text(23, 45, r'$\\mu=15, b=3$')\n",
        "  # maxfreq = n.max()\n",
        "  # # Set a clean upper y-axis limit.\n",
        "  # plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
        "  data.plot.hist(grid=True, bins=30, rwidth=0.9, color='#607c8e')\n",
        "  plt.title(\"Next day's closing change categories\")\n",
        "  plt.xlabel('Counts')\n",
        "  plt.ylabel('Value')\n",
        "  plt.grid(axis='y', alpha=0.75)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dZteu8b1o2gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### main program ###############################\n",
        "\n",
        "#########################\n",
        "# read data source files\n",
        "#########################\n",
        "# read HSI data source\n",
        "dataset = read_csv('data/HSI.csv',header=0,parse_dates=[0],date_parser=parser,index_col=0)\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "# read candlesticks patterns\n",
        "candlesticks = read_csv('data/candlesticks_patterns.csv',header=0,parse_dates=[0],date_parser=parser,index_col=0)\n",
        "\n",
        "# define outcomes dataframe\n",
        "outcomes = DataFrame(index=dataset.index)\n",
        "\n",
        "# features dataset\n",
        "#getCandleSticks(candlesticks)\n",
        "getRSIChange(dataset)\n",
        "#getCloseChange(dataset)\n",
        "# getRocOFCloseChange(dataset)\n",
        "getSMA(dataset)\n",
        "#getVolumnChange(dataset)\n",
        "getPrevCloseTrend(dataset)\n",
        "#encodingExmaple()\n",
        "\n",
        "# outcomes dataset\n",
        "createOutcomesDataframe(dataset)\n",
        "\n",
        "# visualize data\n",
        "#outcomes['close_1_CAT'] = pd.cut(outcomes['close_1'], 8)\n",
        "#showHistogram(outcomes['close_1'])\n",
        "\n",
        "# combine features dataset and outcomes dataset\n",
        "y = outcomes.nextclose_price_trend\n",
        "#X = dataset\n",
        "X = dataset[[\n",
        "  'Open','High','Low','Close','Adj Close','Volume',\n",
        "  'RSI_5day_vs_prevday','smaDiff_5_14','prevclose_price_trend'\n",
        "]].copy()\n",
        "Xy = X.join(y).dropna()\n",
        "y = Xy[y.name]\n",
        "X = Xy[X.columns]\n",
        "print(y.shape)\n",
        "print(X.shape)\n",
        "\n",
        "# print(Xy.head(20))\n",
        "\n",
        "# print(Xy.columns)\n",
        "\n",
        "# Visualize correslation between variables\n",
        "# Correction Matrix Plot\n",
        "# Convert the input into a 2D dictionary\n",
        "df_copy = Xy[[\n",
        "  'RSI_5day_vs_prevday','smaDiff_5_14','prevclose_price_trend','nextclose_price_trend'\n",
        "]].copy()\n",
        "df_copy2 = Xy[[\n",
        "  'Open','Close','High','Low','Volume'\n",
        "]].copy()\n",
        "#corr = df_copy2.corr(method='pearson')\n",
        "#print(corr)\n",
        "\n",
        "#####\n",
        "# Create the plot\n",
        "#####\n",
        "#plt.pcolormesh(df, edgecolors='black')\n",
        "#plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n",
        "#plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)"
      ],
      "metadata": {
        "id": "PMzGkkHmo8Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# output to CSV and exit\n",
        "########################\n",
        "dataset = dataset.dropna()\n",
        "Xy.to_csv('data/preprocessed_features_2.csv')\n",
        "#sys.exit()\n"
      ],
      "metadata": {
        "id": "iSAfXOexpCu5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}