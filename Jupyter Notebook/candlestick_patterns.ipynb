{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rckaisen/stock_backtrader/blob/main/stock_backtesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiLVPPrrYL1j"
      },
      "outputs": [],
      "source": [
        "# Detect candlesticks patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfqXkm6-ch8H"
      },
      "outputs": [],
      "source": [
        "# download TA-Lib\n",
        "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24p_-QS8cz7S",
        "outputId": "2f805489-9fdd-4e05-e0fd-eb8797ba7d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data  ta-lib-0.4.0-src.tar.gz\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_jrGxRWc1Fg"
      },
      "outputs": [],
      "source": [
        "!tar xvzf ta-lib-0.4.0-src.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "427zDmhmc8C2",
        "outputId": "385ab8f9-ed0c-4068-b913-5e4b90fbf9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data  ta-lib  ta-lib-0.4.0-src.tar.gz\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvYfuPBYc-bO"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LcO9iuJdEB1"
      },
      "outputs": [],
      "source": [
        "os.chdir('ta-lib') # Can't use !cd in co-lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBz8MAgydHAR"
      },
      "outputs": [],
      "source": [
        "!./configure --prefix=/usr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzBhxdw9dI-z"
      },
      "outputs": [],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sntr627DdK5N"
      },
      "outputs": [],
      "source": [
        "!make install\n",
        "# wait ~ 30s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTWgTeaxdP7Y"
      },
      "outputs": [],
      "source": [
        "os.chdir('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuyY-nYadSmh",
        "outputId": "755e1e3a-9b1c-427a-e70e-0b9967b9aab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data  ta-lib  ta-lib-0.4.0-src.tar.gz\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf15I1GYYL1r"
      },
      "outputs": [],
      "source": [
        "!pip install TA-Lib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz0POirinZ55"
      },
      "source": [
        "# **Part 1: Capture candlestick patterns from stock price data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q66JTyGZYL1s",
        "outputId": "be66de74-4696-4637-99cf-453209024e34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-4ddc050ab014>:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  from pandas import datetime\n"
          ]
        }
      ],
      "source": [
        "# Main program\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from pandas import concat\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import talib\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS-K35sNkMqK"
      },
      "outputs": [],
      "source": [
        "# parsing date function\n",
        "def parser(x):\n",
        "    return datetime.strptime(x,'%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHBWld-VkMqK"
      },
      "outputs": [],
      "source": [
        "# read csv file using specified parsing function and index column is the first column (index=0)\n",
        "dataset = read_csv('HSI.csv',header=0,parse_dates=[0],date_parser=parser,index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAU474hmkMqK"
      },
      "outputs": [],
      "source": [
        "# remove NaN values, drop 'Adj Close' column\n",
        "dataset = dataset.dropna().drop(['Adj Close'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df8otj1UkMqK",
        "outputId": "0de1d8a3-5ab9-49e2-ee7c-178b6bf5f2c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   Open         High          Low        Close  Volume\n",
            "Date                                                                  \n",
            "1986-12-31  2568.300049  2568.300049  2568.300049  2568.300049     0.0\n",
            "1987-01-02  2540.100098  2540.100098  2540.100098  2540.100098     0.0\n",
            "1987-01-05  2552.399902  2552.399902  2552.399902  2552.399902     0.0\n",
            "1987-01-06  2583.899902  2583.899902  2583.899902  2583.899902     0.0\n",
            "1987-01-07  2607.100098  2607.100098  2607.100098  2607.100098     0.0\n",
            "1987-01-08  2603.300049  2603.300049  2603.300049  2603.300049     0.0\n",
            "1987-01-09  2561.699951  2561.699951  2561.699951  2561.699951     0.0\n",
            "1987-01-12  2614.899902  2614.899902  2614.899902  2614.899902     0.0\n",
            "1987-01-13  2590.800049  2590.800049  2590.800049  2590.800049     0.0\n",
            "1987-01-14  2578.199951  2578.199951  2578.199951  2578.199951     0.0\n",
            "Dataset shape:  (7936, 5)\n"
          ]
        }
      ],
      "source": [
        "# preview the dataset\n",
        "print(dataset.head(n=10))\n",
        "print(\"Dataset shape: \", dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6TcqgojkMqK"
      },
      "outputs": [],
      "source": [
        "# set arrays of open, high, low and close prices\n",
        "pOpen = dataset['Open'].values\n",
        "pHigh = dataset['High'].values\n",
        "pLow = dataset['Low'].values\n",
        "pClose = dataset['Close'].values\n",
        "volume = dataset['Volume'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGIfxJElkMqL"
      },
      "outputs": [],
      "source": [
        "# make a copy of the dataset\n",
        "df = dataset.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzr-W-tTkMqL"
      },
      "outputs": [],
      "source": [
        "# Two Crows (-100 denotes bearish)\n",
        "patternName = 'CDL2CROWS'\n",
        "output = talib.CDL2CROWS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three Black Crows (-100 denotes bearish)\n",
        "patternName = 'CDL3BLACKCROWS'\n",
        "output = talib.CDL3BLACKCROWS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three Inside Up/Down (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDL3INSIDE'\n",
        "output = talib.CDL3INSIDE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three-Line Strike (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDL3LINESTRIKE'\n",
        "output = talib.CDL3LINESTRIKE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three Outside Up/Down (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDL3OUTSIDE'\n",
        "output = talib.CDL3OUTSIDE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA7Oji7LkMqL"
      },
      "outputs": [],
      "source": [
        "# Three Stars In The South (+100 denotes bullish)\n",
        "patternName = 'CDL3STARSINSOUTH'\n",
        "output = talib.CDL3STARSINSOUTH(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Three Advancing White Soldiers (+100 denotes bullish)\n",
        "patternName = 'CDL3WHITESOLDIERS'\n",
        "output = talib.CDL3WHITESOLDIERS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Abandoned Baby (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLABANDONEDBABY'\n",
        "output = talib.CDLABANDONEDBABY(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Advance Block (-100 denotes bearish)\n",
        "patternName = 'CDLADVANCEBLOCK'\n",
        "output = talib.CDLADVANCEBLOCK(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Belt-hold (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLBELTHOLD'\n",
        "output = talib.CDLBELTHOLD(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqsfFT0jkMqM"
      },
      "outputs": [],
      "source": [
        "# Breakaway (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLBREAKAWAY'\n",
        "output = talib.CDLBREAKAWAY(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Closing Marubozu (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLCLOSINGMARUBOZU'\n",
        "output = talib.CDLCLOSINGMARUBOZU(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Concealing Baby Swallow (+100 denotes bullish)\n",
        "patternName = 'CDLCONCEALBABYSWALL'\n",
        "output = talib.CDLCONCEALBABYSWALL(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Counterattack (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLCOUNTERATTACK'\n",
        "output = talib.CDLCOUNTERATTACK(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Dark Cloud Cover (-100 denotes bearish)\n",
        "patternName = 'CDLDARKCLOUDCOVER'\n",
        "output = talib.CDLDARKCLOUDCOVER(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eekU4sPkMqN"
      },
      "outputs": [],
      "source": [
        "# Doji (+100 denotes bullish)\n",
        "patternName = 'CDLDOJI'\n",
        "output = talib.CDLDOJI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Doji Star (-100 denotes bearlish, +100 denotes bullish)\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][p\n",
        "patternName = 'CDLDOJISTAR'\n",
        "output = talib.CDLDOJISTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Dragonfly Doji (+100 denotes bullish)\n",
        "patternName = 'CDLDRAGONFLYDOJI'\n",
        "output = talib.CDLDRAGONFLYDOJI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Engulfing Pattern (-100 denotes bearlish, +100 denotes bullish)\n",
        "patternName = 'CDLENGULFING'\n",
        "output = talib.CDLENGULFING(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Evening Doji Star (-100 denotes bearlish)\n",
        "patternName = 'CDLEVENINGDOJISTAR'\n",
        "output = talib.CDLEVENINGDOJISTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuAj5tCYkMqN"
      },
      "outputs": [],
      "source": [
        "# Evening Star (-100 denotes bearlish)\n",
        "patternName = 'CDLEVENINGSTAR'\n",
        "output = talib.CDLEVENINGSTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Up/Down-gap side-by-side white lines (-100 denotes bearlish, +100 denotes bullish)\n",
        "patternName = 'CDLGAPSIDESIDEWHITE'\n",
        "output = talib.CDLGAPSIDESIDEWHITE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Gravestone Doji (+100 denotes bullish)\n",
        "patternName = 'CDLGRAVESTONEDOJI'\n",
        "output = talib.CDLGRAVESTONEDOJI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Hammer (+100 denotes bullish)\n",
        "patternName = 'CDLHAMMER'\n",
        "output = talib.CDLHAMMER(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Hanging Man (-100 denotes bearish)\n",
        "patternName = 'CDLHANGINGMAN'\n",
        "output = talib.CDLHANGINGMAN(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRvoK6TbkMqO"
      },
      "outputs": [],
      "source": [
        "# Harami Pattern (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLHARAMI'\n",
        "output = talib.CDLHARAMI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Harami Cross Pattern (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLHARAMICROSS'\n",
        "output = talib.CDLHARAMICROSS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# High-Wave Candle (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLHIGHWAVE'\n",
        "output = talib.CDLHIGHWAVE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Hikkake Pattern\n",
        "patternName = 'CDLHIKKAKE'\n",
        "output = talib.CDLHIKKAKE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Modified Hikkake Pattern\n",
        "patternName = 'CDLHIKKAKEMOD'\n",
        "output = talib.CDLHIKKAKEMOD(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3CBMNLakMqO"
      },
      "outputs": [],
      "source": [
        "# Homing Pigeon (+100 denotes bullish)\n",
        "patternName = 'CDLHOMINGPIGEON'\n",
        "output = talib.CDLHOMINGPIGEON(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Identical Three Crows (-100 denotes bearish)\n",
        "patternName = 'CDLIDENTICAL3CROWS'\n",
        "output = talib.CDLIDENTICAL3CROWS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# In-Neck Pattern (-100 denotes bearish)\n",
        "patternName = 'CDLINNECK'\n",
        "output = talib.CDLINNECK(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Inverted Hammer (+100 denotes bullish)\n",
        "patternName = 'CDLINVERTEDHAMMER'\n",
        "output = talib.CDLINVERTEDHAMMER(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Kicking (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLKICKING'\n",
        "output = talib.CDLKICKING(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JaioAaqkMqO"
      },
      "outputs": [],
      "source": [
        "# Kicking - bull/bear determined by the longer marubozu (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLKICKINGBYLENGTH'\n",
        "output = talib.CDLKICKINGBYLENGTH(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Ladder Bottom (+100 denotes bullish)\n",
        "patternName = 'CDLLADDERBOTTOM'\n",
        "output = talib.CDLLADDERBOTTOM(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Long Legged Doji (+100 denotes bullish)\n",
        "patternName = 'CDLLONGLEGGEDDOJI'\n",
        "output = talib.CDLLONGLEGGEDDOJI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Long Line Candle (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLLONGLINE'\n",
        "output = talib.CDLLONGLINE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Marubozu (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLMARUBOZU'\n",
        "output = talib.CDLMARUBOZU(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP1ayq3ikMqP"
      },
      "outputs": [],
      "source": [
        "# Matching Low (+100 denotes bullish)\n",
        "patternName = 'CDLMATCHINGLOW'\n",
        "output = talib.CDLMATCHINGLOW(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Mat Hold (+100 denotes bullish)\n",
        "patternName = 'CDLMATHOLD'\n",
        "output = talib.CDLMATHOLD(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Morning Doji Star (+100 denotes bullish)\n",
        "patternName = 'CDLMORNINGDOJISTAR'\n",
        "output = talib.CDLMORNINGDOJISTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Morning Star (+100 denotes bullish)\n",
        "patternName = 'CDLMORNINGSTAR'\n",
        "output = talib.CDLMORNINGSTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# On-Neck Pattern (-100 denotes bearish)\n",
        "patternName = 'CDLONNECK'\n",
        "output = talib.CDLONNECK(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFQNYb7EkMqP"
      },
      "outputs": [],
      "source": [
        "# Piercing Pattern (+100 denotes bullish)\n",
        "patternName = 'CDLPIERCING'\n",
        "output = talib.CDLPIERCING(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Rickshaw Man (+100 denotes bullish)\n",
        "patternName = 'CDLRICKSHAWMAN'\n",
        "output = talib.CDLRICKSHAWMAN(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Rising/Falling Three Methods (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLRISEFALL3METHODS'\n",
        "output = talib.CDLRISEFALL3METHODS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Separating Lines (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLSEPARATINGLINES'\n",
        "output = talib.CDLSEPARATINGLINES(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Shooting Star (-100 denotes bearish)\n",
        "patternName = 'CDLSHOOTINGSTAR'\n",
        "output = talib.CDLSHOOTINGSTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1rRhOjOkMqP"
      },
      "outputs": [],
      "source": [
        "# Short Line Candle (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLSHORTLINE'\n",
        "output = talib.CDLSHORTLINE(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Spinning Top (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLSPINNINGTOP'\n",
        "output = talib.CDLSPINNINGTOP(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Stalled Pattern (-100 denotes bearish)\n",
        "patternName = 'CDLSTALLEDPATTERN'\n",
        "output = talib.CDLSTALLEDPATTERN(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Stick Sandwich (-100 denotes bearish)\n",
        "patternName = 'CDLSTICKSANDWICH'\n",
        "output = talib.CDLSTICKSANDWICH(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Takuri (Dragonfly Doji with very long lower shadow) (+100 denotes bullish)\n",
        "patternName = 'CDLTAKURI'\n",
        "output = talib.CDLTAKURI(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wx7cjKckMqP"
      },
      "outputs": [],
      "source": [
        "# Tasuki Gap (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLTASUKIGAP'\n",
        "output = talib.CDLTASUKIGAP(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Thrusting Pattern (-100 denotes bearish)\n",
        "patternName = 'CDLTHRUSTING'\n",
        "output = talib.CDLTHRUSTING(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Tristar Pattern (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLTRISTAR'\n",
        "output = talib.CDLTRISTAR(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Unique 3 River (+100 denotes bullish)\n",
        "patternName = 'CDLUNIQUE3RIVER'\n",
        "output = talib.CDLUNIQUE3RIVER(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Upside Gap Two Crows (-100 denotes bearish)\n",
        "patternName = 'CDLUPSIDEGAP2CROWS'\n",
        "output = talib.CDLUPSIDEGAP2CROWS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])\n",
        "\n",
        "# Upside/Downside Gap Three Methods (-100 denotes bearish, +100 denotes bullish)\n",
        "patternName = 'CDLXSIDEGAP3METHODS'\n",
        "output = talib.CDLXSIDEGAP3METHODS(pOpen, pHigh, pLow, pClose)\n",
        "df[patternName] = output\n",
        "#print(patternName, \": \\n\", df[df[patternName] != 0][patternName])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IkmaPQIkMqQ"
      },
      "outputs": [],
      "source": [
        "df.to_csv('data/candlesticks_patterns.csv')\n",
        "#sys.exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-zcmnConP5Q"
      },
      "source": [
        "# **Part 2: Preprocessing features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9td0Ir6nyby",
        "outputId": "d881634a-376c-41eb-92bb-05736eb7c791"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-39-e783e2964047>:22: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  from pandas import datetime\n"
          ]
        }
      ],
      "source": [
        "############################################\n",
        "# Preprocessing features and output to file\n",
        "#\n",
        "# Output file: preprocessed_features.csv\n",
        "############################################\n",
        "\n",
        "####\n",
        "# open\n",
        "# close\n",
        "# low\n",
        "# high\n",
        "# volume\n",
        "# RSI(14)\n",
        "# MACD(12,26), EMA(9), Divergence\n",
        "# SMA(10), SMA(20), SMA(50), SMA(100), SMA(200)\n",
        "# OBV\n",
        "# ROC\n",
        "####\n",
        "\n",
        "\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from pandas import concat\n",
        "from pandas import DataFrame\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import talib\n",
        "import sys\n",
        "import six\n",
        "import pywt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_q25CSZn6v7"
      },
      "outputs": [],
      "source": [
        "# parsing date\n",
        "def parser(x):\n",
        "  return datetime.strptime(x,'%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EV22aQPoA1T"
      },
      "outputs": [],
      "source": [
        "# Class labeling for positive and negative number\n",
        "def classlabeling(diff):\n",
        "  if (diff >= 0):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3Ic38F8oDiv"
      },
      "outputs": [],
      "source": [
        "# Calculate percentage change\n",
        "pct_chg_fxn = lambda x: x.pct_change()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBTAhQWToFnT"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# Candlesticks Patterns\n",
        "########################\n",
        "def getCandleSticks(candlesticks):\n",
        "  #print(candlesticks.shape)\n",
        "\n",
        "  start = 5\n",
        "  end = 66\n",
        "  candles = candlesticks.iloc[:,start:end]\n",
        "  #print(candles.shape)\n",
        "\n",
        "  candles = candles.clip(-100,100)\n",
        "  candles = candles.replace(to_replace=100, value=1)\n",
        "  candles = candles.replace(to_replace=-100, value=-1)\n",
        "  candles = candles.sum(axis=1)\n",
        "  dataset['candlesticks'] = candles.clip(-3,3)\n",
        "  dataset['candlesticks'] = dataset['candlesticks'].shift(1).fillna(0).astype('int')\n",
        "  #print(dataset.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d17x1PySoJLt"
      },
      "outputs": [],
      "source": [
        "##############\n",
        "# RSI Change\n",
        "##############\n",
        "def categorizeRSI(rsi):\n",
        "  if (rsi >= 70):\n",
        "    return 2\n",
        "  elif (rsi <= 30):\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdnGlm68oRli"
      },
      "outputs": [],
      "source": [
        "def RSI_1hot(rsi):\n",
        "  encoder = OneHotEncoder()\n",
        "  lb = LabelBinarizer()\n",
        "  df_cat_1hot = encoder.fit_transform(rsi)\n",
        "  print(\"1hot: \", df_cat_1hot.toarray())\n",
        "  x = lb.fit_transform(np.array(df_cat_1hot.toarray()))\n",
        "  print(\"lb: \", x)\n",
        "  y = lb.inverse_transform(x)\n",
        "  print(\"lb: \", y)\n",
        "  #print(\"check: \", encoder.transform([[0,1], [1,2], [2,1], [1,0], [0,2], [2,0], [0,0], [1,1], [2,2]]).toarray())\n",
        "  #return df_cat_1hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKBTZzjloTr6"
      },
      "outputs": [],
      "source": [
        "def convert(v, cat):\n",
        "  if (v == True):\n",
        "    return cat\n",
        "  elif (v == False):\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAisTtemoVz3"
      },
      "outputs": [],
      "source": [
        "def relabel(val):\n",
        "  if (val == 1):\n",
        "    #return \"noChange_below30\"\n",
        "    return 1\n",
        "  elif (val == 2):\n",
        "    #return \"noChange_btw30and70\"\n",
        "    return 2\n",
        "  elif (val == 3):\n",
        "    #return \"noChange_above70\"\n",
        "    return 3\n",
        "  elif (val == 4):\n",
        "    #return \"below30_to_btw30and70\"\n",
        "    return 4\n",
        "  elif (val == 5):\n",
        "    #return \"btw30and70_to_above70\"\n",
        "    return 5\n",
        "  elif (val == 6):\n",
        "    #return \"above70_to_btw30and70\"\n",
        "    return 6\n",
        "  elif (val == 7):\n",
        "    #return \"btw30and70_to_below30\"\n",
        "    return 7\n",
        "  elif (val == 8):\n",
        "    #return \"below30_to_above70\"\n",
        "    return 8\n",
        "  elif (val == 9):\n",
        "    #return \"above70_to_below30\"\n",
        "    return 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljAHUu4boYqd"
      },
      "outputs": [],
      "source": [
        "def RSI_patterns(a, b):\n",
        "  # prev=0, curr=0 (both previous RSI and current RSI are below 30)\n",
        "  pattern1 = np.logical_and(a==0, b==0)\n",
        "  pattern1 = pattern1.apply(lambda v: convert(v, 1))\n",
        "  # prev=1, curr=1 (both previous RSI and current RSI are between 30 and 70)\n",
        "  pattern2 = np.logical_and(a==1, b==1)\n",
        "  pattern2 = pattern2.apply(lambda v: convert(v, 2))\n",
        "  # prev=2, curr=2 (both previous RSI and current RSI are above 70)\n",
        "  pattern3 = np.logical_and(a==2, b==2)\n",
        "  pattern3 = pattern3.apply(lambda v: convert(v, 3))\n",
        "  # prev=0, curr=1 (previous RSI below 30 goes up to current RSI 30~70 range)\n",
        "  pattern4 = np.logical_and(a==0, b==1)\n",
        "  pattern4 = pattern4.apply(lambda v: convert(v, 4))\n",
        "  # prev=1, curr=2 (previous RSI 30~70 range goes up to current RSI above 70)\n",
        "  pattern5 = np.logical_and(a==1, b==2)\n",
        "  pattern5 = pattern5.apply(lambda v: convert(v, 5))\n",
        "  # prev=2, curr=1 (previous RSI above 70 goes down to current RSI 30~70 range)\n",
        "  pattern6 = np.logical_and(a==2, b==1)\n",
        "  pattern6 = pattern6.apply(lambda v: convert(v, 6))\n",
        "  # prev=1, curr=0 (previous RSI 30~70 range goes down to current RSI below 30)\n",
        "  pattern7 = np.logical_and(a==1, b==0)\n",
        "  pattern7 = pattern7.apply(lambda v: convert(v, 7))\n",
        "  # prev=0, curr=2 (previous RSI below 30 goes up to current RSI above 70)\n",
        "  pattern8 = np.logical_and(a==0, b==2)\n",
        "  pattern8 = pattern8.apply(lambda v: convert(v, 8))\n",
        "  # prev=2, curr=0 (previous RSI above 70 goes down to current RSI below 30)\n",
        "  pattern9 = np.logical_and(a==2, b==0)\n",
        "  pattern9 = pattern9.apply(lambda v: convert(v, 9))\n",
        "  # add all columns element-wise\n",
        "  dataset['RSI_5day_vs_prevday'] = np.add(np.add(np.add(np.add(np.add(np.add(np.add(np.add(pattern1, pattern2), pattern3), pattern4), pattern5), pattern6), pattern7), pattern8), pattern9)\n",
        "  dataset['RSI_5day_vs_prevday'] = dataset['RSI_5day_vs_prevday'].shift(-5).fillna(1).astype('int')\n",
        "  dataset['RSI_5day_vs_prevday'] = dataset['RSI_5day_vs_prevday'].apply(lambda v: relabel(v))\n",
        "  #return pattern1, pattern2, pattern3, pattern4, pattern5, pattern6, pattern7, pattern8, pattern9\n",
        "  #return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHH-AAYGocR-"
      },
      "outputs": [],
      "source": [
        "def getRSIChange(dataset):\n",
        "  # Compute RSI of close price\n",
        "  rsi = talib.RSI(dataset[\"Close\"].values, timeperiod=14)\n",
        "  #print(rsi.shape)\n",
        "\n",
        "  # Add columns of RSI and RSI Change dataset\n",
        "  # Use diff() to calculate difference\n",
        "  # Use pct_change() to calculate pct_change() (not used in current setting)\n",
        "  # Use categorizeRSI() to classify RSI value level (not used in current setting)\n",
        "  dataset['RSI'] = rsi\n",
        "  dataset['RSI_PREV'] = dataset['RSI'].shift(1).fillna(0).astype('int')\n",
        "  dataset['RSI_PREV_CAT'] = dataset['RSI_PREV'].apply(lambda d: categorizeRSI(d))\n",
        "  #dataset['RSI_CAT'] = dataset['RSI'].apply(lambda d: categorizeRSI(d))\n",
        "  #dataset['RSI_CAT_PREV'] = dataset['RSI_CAT'].shift(1).fillna(0).astype('int')\n",
        "  #dataset['RSI_CAT_NEXT'] = dataset['RSI_CAT'].shift(-1).fillna(0).astype('int')\n",
        "  #dataset['RSI_CHG'] = dataset['RSI'].diff()\n",
        "  #dataset['RSI_CHG_CAT'] = dataset['RSI_CHG'].apply(lambda d: classlabeling(d))\n",
        "  #dataset['RSI_CHG_ROC'] = dataset['RSI_CHG'].pct_change()\n",
        "  dataset['RSI_AVG_5DAYS'] = talib.SMA(dataset['RSI_PREV'], timeperiod=5).fillna(0).astype('int').shift(-5)\n",
        "  dataset['RSI_AVG_5DAYS_CAT'] = dataset['RSI_AVG_5DAYS'].apply(lambda d: categorizeRSI(d))\n",
        "  # compare RSI_AVG_5DAYS_CAT and RSI_CAT_PREV\n",
        "  dataset = dataset.dropna()\n",
        "\n",
        "\n",
        "  # df_encoded, df_categories = dataset[['RSI_CAT_PREV','RSI_CAT']].factorize()\n",
        "  # print(\"2: \", df_encoded[:])\n",
        "  # print(\"3: \", df_categories[:])\n",
        "  #RSI_1hot(dataset[['RSI_CAT_PREV','RSI_CAT']])\n",
        "  #dataset['NoChange_below30'], dataset['NoChange_normal'], dataset['NoChange_above70'], dataset['below30_to_normal'], dataset['normal_to_above70'], dataset['above70_to_normal'], dataset['normal_to_below30'], dataset['below30_to_above70'], dataset['above70_to_below30'] = check(dataset['RSI_AVG_5DAYS_CAT'], dataset['RSI_PREV_CAT'])\n",
        "  #dataset['RSI_5day_vs_prevday'] = RSI_patterns(dataset['RSI_AVG_5DAYS_CAT'], dataset['RSI_PREV_CAT'])\n",
        "  RSI_patterns(dataset['RSI_AVG_5DAYS_CAT'], dataset['RSI_PREV_CAT'])\n",
        "  # skip first 5 rows because of RSI average 5 days\n",
        "  #print(dataset[5:])\n",
        "\n",
        "  #plt.hist(dataset['RSI'], bins = 30)\n",
        "  #plt.xlabel(\"Number\")\n",
        "  #plt.ylabel(\"Frequency\")\n",
        "  #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uEtGYkWogz2"
      },
      "outputs": [],
      "source": [
        "#####################\n",
        "# Close Price Change\n",
        "#####################\n",
        "def getCloseChange(dataset):\n",
        "  dataset['CLOSE_CHG'] = dataset['Close'].diff()\n",
        "  dataset['CLOSE_CHG_CAT'] = dataset['CLOSE_CHG'].shift(1).apply(lambda d: classlabeling(d))\n",
        "  #dataset['Close_LOG'] = np.log(dataset['Close'])\n",
        "  #dataset = dataset.dropna()\n",
        "  #print(dataset.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tsu_p5szolIb"
      },
      "outputs": [],
      "source": [
        "#########################################\n",
        "# feature: Rate of change of close price\n",
        "#########################################\n",
        "def roc_slope(df, days):\n",
        "  sma = talib.SMA(df, timeperiod=days)\n",
        "  rocOfValue = talib.ROCP(sma, timeperiod=days)\n",
        "  rocOfValueChange = talib.ROCP(rocOfValue, timeperiod=days)\n",
        "  rocOfValueChangeCat = rocOfValueChange.apply(lambda d: 1 if d>=0 else -1)\n",
        "  return rocOfValueChange, rocOfValueChangeCat\n",
        "\n",
        "def getRocOFCloseChange(dataset):\n",
        "  # Calculate ROC of value change of SMA of 2 days\n",
        "  dataset['rocOFCloseChange'], dataset['rocOFCloseChangeCat'] = roc_slope(dataset['Close'], 2)\n",
        "  #dataset = dataset.dropna()\n",
        "  #print(dataset.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLD4Bn6-ol-3"
      },
      "outputs": [],
      "source": [
        "################\n",
        "# feature: SMA\n",
        "################\n",
        "def smaDiff(d1, d2, l1, l2):\n",
        "  diff1 = (d1 - d2).apply(lambda d: 1 if  d>=0 else -1)  # previous day\n",
        "  dataset['diff1'] = diff1\n",
        "  diff2 = diff1.shift(1).apply(lambda d: 1 if  d>=0 else -1)  # previous two days\n",
        "  dataset['diff2'] = diff2\n",
        "\n",
        "  dataset['test1'] = ((diff1 == 1) & (diff2 == 1)).apply(lambda x: 1 if x==True else 0) # sma5 above sma14\n",
        "  dataset['test2'] = ((diff1 == 1) & (diff2 == -1)).apply(lambda x: 2 if x==True else 0) # sma5 cross below sma14\n",
        "  dataset['test3'] = ((diff1 == -1) & (diff2 == 1)).apply(lambda x: 3 if x==True else 0) # sma5 cross above sma14\n",
        "  dataset['test4'] = ((diff1 == -1) & (diff2 == -1)).apply(lambda x: 4 if x==True else 0) # sma5 below sma14\n",
        "  #dataset['smaDiff_5_14'] = (np.add(np.add(np.add(dataset['test1'], dataset['test2']), dataset['test3']), dataset['test4'])).apply(lambda x: 'sma5_above_sma14' if x==1 else 'sma_cross_below_sma14' if x==2 else 'sma5_cross_above_sma14' if x==3 else 'sma5_below_sma14')\n",
        "  dataset['smaDiff_5_14'] = (np.add(np.add(np.add(dataset['test1'], dataset['test2']), dataset['test3']), dataset['test4']))\n",
        "\n",
        "  #result = (diff1 - diff2).apply(lambda d: l1+\"_cross_above_\"+l2 if d==-2 else (l1+\"_cross_below_\"+l2 if d==2 else \"sma_normal\"))\n",
        "  #print(dataset.head(50))\n",
        "  #return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpEIQgmOooWM"
      },
      "outputs": [],
      "source": [
        "def getSMA(dataset):\n",
        "  dataset['sma5'] = talib.SMA(dataset.Close, timeperiod=5)\n",
        "  dataset['sma14'] = talib.SMA(dataset.Close, timeperiod=14)\n",
        "  #dataset['sma50'] = talib.SMA(dataset.Close, timeperiod=50)\n",
        "  #dataset['sma200'] = talib.SMA(dataset.Close, timeperiod=200)\n",
        "  #dataset.dropna(inplace=True)\n",
        "  smaDiff(dataset['sma5'], dataset['sma14'], 'sma5', 'sma14')\n",
        "  #dataset['smaDiff_5_14'] = smaDiff(dataset['sma5'], dataset['sma14'], 'sma5', 'sma14')\n",
        "  #dataset['smaDiff_5_50'] = smaDiff(dataset['sma5'], dataset['sma50'], 'sma5', 'sma50')\n",
        "  #dataset['smaDiff_5_200'] = smaDiff(dataset['sma5'], dataset['sma200'], 'sma5', 'sma200')\n",
        "  #dataset['smaDiff_14_50'] = smaDiff(dataset['sma14'], dataset['sma50'], 'sma14', 'sma50')\n",
        "  #dataset['smaDiff_14_200'] = smaDiff(dataset['sma14'], dataset['sma200'], 'sma14', 'sma200')\n",
        "  #dataset['smaDiff_50_200'] = smaDiff(dataset['sma50'], dataset['sma200'], 'sma50', 'sma200')\n",
        "  #print(dataset.head(30))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIatM1r1oqZ9"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "# feature: Volume\n",
        "##################\n",
        "def getVolumnChange(dataset):\n",
        "  dataset['OBV'] = talib.OBV(dataset[\"Close\"], dataset[\"Volume\"])\n",
        "  dataset['Volume_CHG'] = dataset['Volume'].shift(1).pct_change()\n",
        "  dataset['prev1_volume'] = dataset['Volume'].shift(1)\n",
        "  dataset['prev2_volume'] = dataset['Volume'].shift(2)\n",
        "  dataset['prev3_volume'] = dataset['Volume'].shift(3)\n",
        "  dataset['sma5_volume'] = talib.SMA(dataset.prev1_volume, timeperiod=5)\n",
        "\n",
        "  check_vol_uptrend(dataset['prev1_volume'], dataset['prev2_volume'], dataset['prev3_volume'], dataset['sma5_volume'])\n",
        "  check_vol_downtrend(dataset['prev1_volume'], dataset['prev2_volume'], dataset['prev3_volume'], dataset['sma5_volume'])\n",
        "  dataset.dropna(inplace=True)\n",
        "  combined_volume_trends(dataset['vol_up_trend'], dataset['vol_down_trend'])\n",
        "\n",
        "# previous 3 days volume greater than sma5_volume\n",
        "def check_vol_uptrend(d1, d2, d3, d4):\n",
        "  dataset['vol_up_trend'] = np.logical_and(np.logical_and(d1>d4, d2>d4), d3>d4)\n",
        "\n",
        "# previous 3 days volume less than sma5_volume\n",
        "def check_vol_downtrend(d1, d2, d3, d4):\n",
        "  dataset['vol_down_trend'] = np.logical_and(np.logical_and(d1<d4, d2<d4), d3<d4)\n",
        "\n",
        "def combined_volume_trends(d1, d2):\n",
        "  dataset['vol_test1'] = ((d1 == False) & (d2 == False)).apply(lambda x: 0 if x==True else 0)\n",
        "  dataset['vol_test2'] = ((d1 == True) & (d2 == False)).apply(lambda x: 1 if x==True else 0)\n",
        "  dataset['vol_test3'] = ((d1 == False) & (d2 == True)).apply(lambda x: 2 if x==True else 0)\n",
        "  dataset['vol_trend'] = (np.add(np.add(dataset['vol_test1'], dataset['vol_test2']), dataset['vol_test3'])).apply(lambda x: 'vol_normal' if x==0 else 'vol_up_trend' if x==1 else 'vol_down_trend')\n",
        "\n",
        "\n",
        "  #dataset = dataset.dropna()\n",
        "  print(dataset.head(60))\n",
        "\n",
        "  quantile_list = [0, .25, .5, .75, 1.]\n",
        "  quantiles = dataset['Volume'].quantile(quantile_list)\n",
        "  #print(\"quantiles: \", quantiles)\n",
        "\n",
        "  # fig, ax = plt.subplots()\n",
        "  # dataset['Volume'].hist(bins=30, color='#A9C5D3', edgecolor='black', grid=False)\n",
        "  # for quantile in quantiles:\n",
        "  #   qvl = plt.axvline(quantile, color='r')\n",
        "  #   ax.legend([qvl], ['Quantiles'], fontsize=10)\n",
        "  #   ax.set_title('Volumn', fontsize=12)\n",
        "  #   ax.set_xlabel('Volumn range', fontsize=12)\n",
        "  #   ax.set_ylabel('Frequency', fontsize=12)\n",
        "\n",
        "  #plt.hist(dataset['Volume'], bins = 30)\n",
        "  #plt.xlabel(\"Number\")\n",
        "  #plt.ylabel(\"Frequency\")\n",
        "  #plt.show()\n",
        "\n",
        "  quantile_labels = ['vol_low', 'vol_medium_low', 'vol_medium_high', 'vol_high']\n",
        "  dataset['volumn_quantile_range'] = pd.qcut(\n",
        "                                            dataset['Volume'],\n",
        "                                            q=quantile_list)\n",
        "  dataset['volumn_quantile_label'] = pd.qcut(\n",
        "                                            dataset['Volume'],\n",
        "                                            q=quantile_list,\n",
        "                                            labels=quantile_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIXyPIvGoxgv"
      },
      "outputs": [],
      "source": [
        "#################################\n",
        "# Get previous close price trend\n",
        "#################################\n",
        "def check_prevclose_uptrend(d1, d2, d3, d4):\n",
        "  dataset['prevclose_up_trend'] = np.logical_and(np.logical_and(d1>d4, d2>d4), d3>d4)\n",
        "\n",
        "# next 3 days close price greater than sma3\n",
        "def check_prevclose_downtrend(d1, d2, d3, d4):\n",
        "  dataset['prevclose_down_trend'] = np.logical_and(np.logical_and(d1<d4, d2<d4), d3<d4)\n",
        "\n",
        "def combined_prevclose_trends(d1, d2):\n",
        "  dataset['test1'] = ((d1 == False) & (d2 == False)).apply(lambda x: 0 if x==True else 0)\n",
        "  dataset['test2'] = ((d1 == True) & (d2 == False)).apply(lambda x: 1 if x==True else 0)\n",
        "  dataset['test3'] = ((d1 == False) & (d2 == True)).apply(lambda x: 2 if x==True else 0)\n",
        "  #dataset['prevclose_price_trend'] = (np.add(np.add(dataset['test1'], dataset['test2']), dataset['test3'])).apply(lambda x: 'prevclose_na' if x==0 else 'prevclose_up_trend' if x==1 else 'prevclose_down_trend')\n",
        "  dataset['prevclose_price_trend'] = (np.add(np.add(dataset['test1'], dataset['test2']), dataset['test3']))\n",
        "\n",
        "def getPrevCloseTrend(dataset):\n",
        "  dataset['prevclose_1'] = dataset.Close.shift(1)\n",
        "  dataset['prevclose_2'] = dataset.Close.shift(2)\n",
        "  dataset['prevclose_3'] = dataset.Close.shift(3)\n",
        "  dataset['prevclose_sma5'] = talib.SMA(dataset['prevclose_1'], timeperiod=5)\n",
        "  check_prevclose_uptrend(dataset['prevclose_1'], dataset['prevclose_2'], dataset['prevclose_3'], dataset['prevclose_sma5'])\n",
        "  check_prevclose_downtrend(dataset['prevclose_1'], dataset['prevclose_2'], dataset['prevclose_3'], dataset['prevclose_sma5'])\n",
        "  #dataset.dropna(inplace=True)\n",
        "  combined_prevclose_trends(dataset['prevclose_up_trend'], dataset['prevclose_down_trend'])\n",
        "  print(dataset.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZteu8b1o2gx"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "# create outcome dataframe\n",
        "###########################\n",
        "# next 3 days close price greater than sma3\n",
        "def check_uptrend(d1, d2, d3, d4):\n",
        "  outcomes['up_trend'] = np.logical_and(np.logical_and(d1>d4, d2>d4), d3>d4)\n",
        "\n",
        "# next 3 days close price greater than sma3\n",
        "def check_downtrend(d1, d2, d3, d4):\n",
        "  outcomes['down_trend'] = np.logical_and(np.logical_and(d1<d4, d2<d4), d3<d4)\n",
        "\n",
        "# combine up_trend and down_trend, re-label for feature association\n",
        "def combined_trends(d1, d2):\n",
        "  outcomes['test1'] = ((d1 == False) & (d2 == False)).apply(lambda x: 0 if x==True else 0)\n",
        "  outcomes['test2'] = ((d1 == True) & (d2 == False)).apply(lambda x: 1 if x==True else 0)\n",
        "  outcomes['test3'] = ((d1 == False) & (d2 == True)).apply(lambda x: 2 if x==True else 0)\n",
        "  #outcomes['nextclose_price_trend'] = (np.add(np.add(outcomes['test1'], outcomes['test2']), outcomes['test3'])).apply(lambda x: 'nextclose_na' if x==0 else 'nextclose_up_trend' if x==1 else 'nextclose_down_trend')\n",
        "  outcomes['nextclose_price_trend'] = (np.add(np.add(outcomes['test1'], outcomes['test2']), outcomes['test3']))\n",
        "\n",
        "def createOutcomesDataframe(dataset):\n",
        "  # next day's opening change\n",
        "  outcomes['Close'] = dataset.Close\n",
        "  #outcomes['open_1'] = dataset.Open.shift(-1)/dataset.Close.shift(0)-1\n",
        "  # next day's closing change\n",
        "  #outcomes['close_1'] = dataset.Close.pct_change(-1)\n",
        "  #outcomes['close_1_CAT'] = dataset.Close.pct_change(-1).apply(lambda d: 1 if d>=0 else -1)\n",
        "  #outcomes['close_5'] = dataset.Close.pct_change(-5)\n",
        "  #outcomes['close_5'] = talib.ROC(dataset['Close'], timeperiod=5).shift(-5)\n",
        "  #outcomes['close_5_CAT'] = outcomes['close_5'].apply(lambda d: 'close_up_5day' if d>=0 else 'close_down_5day')\n",
        "  outcomes['close_1'] = dataset.Close.shift(-1)\n",
        "  outcomes['close_2'] = dataset.Close.shift(-2)\n",
        "  outcomes['close_3'] = dataset.Close.shift(-3)\n",
        "  outcomes['close_4'] = dataset.Close.shift(-4)\n",
        "  outcomes['close_5'] = dataset.Close.shift(-5)\n",
        "  #outcomes['sma5'] = talib.SMA(outcomes['close_5'], timeperiod=5)\n",
        "  outcomes['sma5'] = (outcomes['close_1']+outcomes['close_2']+outcomes['close_3']+outcomes['close_4']+outcomes['close_5'])/5\n",
        "  check_uptrend(outcomes['close_1'], outcomes['close_2'], outcomes['close_3'], outcomes['sma5'])\n",
        "  check_downtrend(outcomes['close_1'], outcomes['close_2'], outcomes['close_3'], outcomes['sma5'])\n",
        "  outcomes.dropna(inplace=True)\n",
        "  combined_trends(outcomes['up_trend'], outcomes['down_trend'])\n",
        "  #print(outcomes.isnull().values.any())\n",
        "  #print(outcomes.tail(15))\n",
        "  print(outcomes.tail(30))\n",
        "\n",
        "def showHistogram(data):\n",
        "  # show histogram of next day's closing change categories\n",
        "  # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
        "  # n, bins, patches = plt.hist(x=data, bins='auto', color='#0504aa', alpha=0.7, rwidth=0.85)\n",
        "  # plt.grid(axis='y', alpha=0.75)\n",
        "  # plt.xlabel('Value Range')\n",
        "  # plt.ylabel('Frequency')\n",
        "  # plt.title(\"Next day's closing change categories\")\n",
        "  # plt.text(23, 45, r'$\\mu=15, b=3$')\n",
        "  # maxfreq = n.max()\n",
        "  # # Set a clean upper y-axis limit.\n",
        "  # plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
        "  data.plot.hist(grid=True, bins=30, rwidth=0.9, color='#607c8e')\n",
        "  plt.title(\"Next day's closing change categories\")\n",
        "  plt.xlabel('Counts')\n",
        "  plt.ylabel('Value')\n",
        "  plt.grid(axis='y', alpha=0.75)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMzGkkHmo8Hr",
        "outputId": "dea54d12-277b-436b-dd0b-383f9ba76601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   Open         High          Low        Close    Adj Close  \\\n",
            "Date                                                                          \n",
            "1986-12-31  2568.300049  2568.300049  2568.300049  2568.300049  2568.300049   \n",
            "1987-01-02  2540.100098  2540.100098  2540.100098  2540.100098  2540.100098   \n",
            "1987-01-05  2552.399902  2552.399902  2552.399902  2552.399902  2552.399902   \n",
            "1987-01-06  2583.899902  2583.899902  2583.899902  2583.899902  2583.899902   \n",
            "1987-01-07  2607.100098  2607.100098  2607.100098  2607.100098  2607.100098   \n",
            "1987-01-08  2603.300049  2603.300049  2603.300049  2603.300049  2603.300049   \n",
            "1987-01-09  2561.699951  2561.699951  2561.699951  2561.699951  2561.699951   \n",
            "1987-01-12  2614.899902  2614.899902  2614.899902  2614.899902  2614.899902   \n",
            "1987-01-13  2590.800049  2590.800049  2590.800049  2590.800049  2590.800049   \n",
            "1987-01-14  2578.199951  2578.199951  2578.199951  2578.199951  2578.199951   \n",
            "1987-01-15  2559.100098  2559.100098  2559.100098  2559.100098  2559.100098   \n",
            "1987-01-16  2542.600098  2542.600098  2542.600098  2542.600098  2542.600098   \n",
            "1987-01-19  2460.500000  2460.500000  2460.500000  2460.500000  2460.500000   \n",
            "1987-01-20  2449.899902  2449.899902  2449.899902  2449.899902  2449.899902   \n",
            "1987-01-21  2533.899902  2533.899902  2533.899902  2533.899902  2533.899902   \n",
            "1987-01-22  2536.899902  2536.899902  2536.899902  2536.899902  2536.899902   \n",
            "1987-01-23  2499.399902  2499.399902  2499.399902  2499.399902  2499.399902   \n",
            "1987-01-26  2484.399902  2484.399902  2484.399902  2484.399902  2484.399902   \n",
            "1987-01-27  2524.000000  2524.000000  2524.000000  2524.000000  2524.000000   \n",
            "1987-01-28  2553.300049  2553.300049  2553.300049  2553.300049  2553.300049   \n",
            "1987-02-02  2585.199951  2585.199951  2585.199951  2585.199951  2585.199951   \n",
            "1987-02-03  2606.399902  2606.399902  2606.399902  2606.399902  2606.399902   \n",
            "1987-02-04  2636.600098  2636.600098  2636.600098  2636.600098  2636.600098   \n",
            "1987-02-05  2672.399902  2672.399902  2672.399902  2672.399902  2672.399902   \n",
            "1987-02-06  2673.600098  2673.600098  2673.600098  2673.600098  2673.600098   \n",
            "1987-02-09  2713.699951  2713.699951  2713.699951  2713.699951  2713.699951   \n",
            "1987-02-10  2694.899902  2694.899902  2694.899902  2694.899902  2694.899902   \n",
            "1987-02-11  2739.500000  2739.500000  2739.500000  2739.500000  2739.500000   \n",
            "1987-02-12  2754.699951  2754.699951  2754.699951  2754.699951  2754.699951   \n",
            "1987-02-13  2740.500000  2740.500000  2740.500000  2740.500000  2740.500000   \n",
            "\n",
            "            Volume        RSI  RSI_PREV  RSI_PREV_CAT  RSI_AVG_5DAYS  ...  \\\n",
            "Date                                                                  ...   \n",
            "1986-12-31     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-02     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-05     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-06     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-07     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-08     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-09     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-12     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-13     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-14     0.0        NaN         0             0            0.0  ...   \n",
            "1987-01-15     0.0        NaN         0             0            9.0  ...   \n",
            "1987-01-16     0.0        NaN         0             0           18.0  ...   \n",
            "1987-01-19     0.0        NaN         0             0           26.0  ...   \n",
            "1987-01-20     0.0        NaN         0             0           34.0  ...   \n",
            "1987-01-21     0.0  46.115612         0             0           44.0  ...   \n",
            "1987-01-22     0.0  46.505917        46             1           44.0  ...   \n",
            "1987-01-23     0.0  42.374141        46             1           46.0  ...   \n",
            "1987-01-26     0.0  40.812206        42             1           49.0  ...   \n",
            "1987-01-27     0.0  46.426580        40             1           52.0  ...   \n",
            "1987-01-28     0.0  50.191288        46             1           56.0  ...   \n",
            "1987-02-02     0.0  53.982762        50             1           58.0  ...   \n",
            "1987-02-03     0.0  56.360234        53             1           61.0  ...   \n",
            "1987-02-04     0.0  59.565107        56             1           62.0  ...   \n",
            "1987-02-05     0.0  63.031047        59             1           64.0  ...   \n",
            "1987-02-06     0.0  63.145103        63             1           65.0  ...   \n",
            "1987-02-09     0.0  66.827514        63             1           66.0  ...   \n",
            "1987-02-10     0.0  63.618150        66             1           66.0  ...   \n",
            "1987-02-11     0.0  67.594169        63             1           67.0  ...   \n",
            "1987-02-12     0.0  68.843848        67             1           68.0  ...   \n",
            "1987-02-13     0.0  66.272630        68             1           68.0  ...   \n",
            "\n",
            "            test3  test4  smaDiff_5_14  prevclose_1  prevclose_2  prevclose_3  \\\n",
            "Date                                                                            \n",
            "1986-12-31      0      4             4          NaN          NaN          NaN   \n",
            "1987-01-02      0      4             4  2568.300049          NaN          NaN   \n",
            "1987-01-05      0      4             4  2540.100098  2568.300049          NaN   \n",
            "1987-01-06      0      4             4  2552.399902  2540.100098  2568.300049   \n",
            "1987-01-07      0      4             4  2583.899902  2552.399902  2540.100098   \n",
            "1987-01-08      0      4             4  2607.100098  2583.899902  2552.399902   \n",
            "1987-01-09      0      4             4  2603.300049  2607.100098  2583.899902   \n",
            "1987-01-12      0      4             4  2561.699951  2603.300049  2607.100098   \n",
            "1987-01-13      0      4             4  2614.899902  2561.699951  2603.300049   \n",
            "1987-01-14      0      4             4  2590.800049  2614.899902  2561.699951   \n",
            "1987-01-15      0      4             4  2578.199951  2590.800049  2614.899902   \n",
            "1987-01-16      0      4             4  2559.100098  2578.199951  2590.800049   \n",
            "1987-01-19      0      4             4  2542.600098  2559.100098  2578.199951   \n",
            "1987-01-20      0      4             4  2460.500000  2542.600098  2559.100098   \n",
            "1987-01-21      0      4             4  2449.899902  2460.500000  2542.600098   \n",
            "1987-01-22      0      4             4  2533.899902  2449.899902  2460.500000   \n",
            "1987-01-23      0      4             4  2536.899902  2533.899902  2449.899902   \n",
            "1987-01-26      0      4             4  2499.399902  2536.899902  2533.899902   \n",
            "1987-01-27      0      4             4  2484.399902  2499.399902  2536.899902   \n",
            "1987-01-28      0      4             4  2524.000000  2484.399902  2499.399902   \n",
            "1987-02-02      0      4             4  2553.300049  2524.000000  2484.399902   \n",
            "1987-02-03      0      0             2  2585.199951  2553.300049  2524.000000   \n",
            "1987-02-04      0      0             1  2606.399902  2585.199951  2553.300049   \n",
            "1987-02-05      0      0             1  2636.600098  2606.399902  2585.199951   \n",
            "1987-02-06      0      0             1  2672.399902  2636.600098  2606.399902   \n",
            "1987-02-09      0      0             1  2673.600098  2672.399902  2636.600098   \n",
            "1987-02-10      0      0             1  2713.699951  2673.600098  2672.399902   \n",
            "1987-02-11      0      0             1  2694.899902  2713.699951  2673.600098   \n",
            "1987-02-12      0      0             1  2739.500000  2694.899902  2713.699951   \n",
            "1987-02-13      0      0             1  2754.699951  2739.500000  2694.899902   \n",
            "\n",
            "            prevclose_sma5  prevclose_up_trend  prevclose_down_trend  \\\n",
            "Date                                                                   \n",
            "1986-12-31             NaN               False                 False   \n",
            "1987-01-02             NaN               False                 False   \n",
            "1987-01-05             NaN               False                 False   \n",
            "1987-01-06             NaN               False                 False   \n",
            "1987-01-07             NaN               False                 False   \n",
            "1987-01-08     2570.360010               False                 False   \n",
            "1987-01-09     2577.360010                True                 False   \n",
            "1987-01-12     2581.679980               False                 False   \n",
            "1987-01-13     2594.179980               False                 False   \n",
            "1987-01-14     2595.560010               False                 False   \n",
            "1987-01-15     2589.779980               False                 False   \n",
            "1987-01-16     2580.939990               False                 False   \n",
            "1987-01-19     2577.120020               False                 False   \n",
            "1987-01-20     2546.240039               False                 False   \n",
            "1987-01-21     2518.060010               False                 False   \n",
            "1987-01-22     2509.200000               False                 False   \n",
            "1987-01-23     2504.759961               False                 False   \n",
            "1987-01-26     2496.119922                True                 False   \n",
            "1987-01-27     2500.899902               False                 False   \n",
            "1987-01-28     2515.719922               False                 False   \n",
            "1987-02-02     2519.599951               False                 False   \n",
            "1987-02-03     2529.259961               False                 False   \n",
            "1987-02-04     2550.659961                True                 False   \n",
            "1987-02-05     2581.100000                True                 False   \n",
            "1987-02-06     2610.779980               False                 False   \n",
            "1987-02-09     2634.839990                True                 False   \n",
            "1987-02-10     2660.539990                True                 False   \n",
            "1987-02-11     2678.239990               False                 False   \n",
            "1987-02-12     2698.819971               False                 False   \n",
            "1987-02-13     2715.279980               False                 False   \n",
            "\n",
            "            prevclose_price_trend  \n",
            "Date                               \n",
            "1986-12-31                      0  \n",
            "1987-01-02                      0  \n",
            "1987-01-05                      0  \n",
            "1987-01-06                      0  \n",
            "1987-01-07                      0  \n",
            "1987-01-08                      0  \n",
            "1987-01-09                      1  \n",
            "1987-01-12                      0  \n",
            "1987-01-13                      0  \n",
            "1987-01-14                      0  \n",
            "1987-01-15                      0  \n",
            "1987-01-16                      0  \n",
            "1987-01-19                      0  \n",
            "1987-01-20                      0  \n",
            "1987-01-21                      0  \n",
            "1987-01-22                      0  \n",
            "1987-01-23                      0  \n",
            "1987-01-26                      1  \n",
            "1987-01-27                      0  \n",
            "1987-01-28                      0  \n",
            "1987-02-02                      0  \n",
            "1987-02-03                      0  \n",
            "1987-02-04                      1  \n",
            "1987-02-05                      1  \n",
            "1987-02-06                      0  \n",
            "1987-02-09                      1  \n",
            "1987-02-10                      1  \n",
            "1987-02-11                      0  \n",
            "1987-02-12                      0  \n",
            "1987-02-13                      0  \n",
            "\n",
            "[30 rows x 28 columns]\n",
            "                   Close       close_1       close_2       close_3  \\\n",
            "Date                                                                 \n",
            "2018-12-21  25753.419922  25651.380859  25478.880859  25504.199219   \n",
            "2018-12-24  25651.380859  25478.880859  25504.199219  25845.699219   \n",
            "2018-12-27  25478.880859  25504.199219  25845.699219  25130.349609   \n",
            "2018-12-28  25504.199219  25845.699219  25130.349609  25064.359375   \n",
            "2018-12-31  25845.699219  25130.349609  25064.359375  25626.029297   \n",
            "2019-01-02  25130.349609  25064.359375  25626.029297  25835.699219   \n",
            "2019-01-03  25064.359375  25626.029297  25835.699219  25875.449219   \n",
            "2019-01-04  25626.029297  25835.699219  25875.449219  26462.320313   \n",
            "2019-01-07  25835.699219  25875.449219  26462.320313  26521.429688   \n",
            "2019-01-08  25875.449219  26462.320313  26521.429688  26667.269531   \n",
            "2019-01-09  26462.320313  26521.429688  26667.269531  26298.330078   \n",
            "2019-01-10  26521.429688  26667.269531  26298.330078  26830.289063   \n",
            "2019-01-11  26667.269531  26298.330078  26830.289063  26902.099609   \n",
            "2019-01-14  26298.330078  26830.289063  26902.099609  26755.630859   \n",
            "2019-01-15  26830.289063  26902.099609  26755.630859  27090.810547   \n",
            "2019-01-16  26902.099609  26755.630859  27090.810547  27196.539063   \n",
            "2019-01-17  26755.630859  27090.810547  27196.539063  27005.449219   \n",
            "2019-01-18  27090.810547  27196.539063  27005.449219  27008.199219   \n",
            "2019-01-21  27196.539063  27005.449219  27008.199219  27120.980469   \n",
            "2019-01-22  27005.449219  27008.199219  27120.980469  27569.189453   \n",
            "2019-01-23  27008.199219  27120.980469  27569.189453  27576.960938   \n",
            "2019-01-24  27120.980469  27569.189453  27576.960938  27531.679688   \n",
            "2019-01-25  27569.189453  27576.960938  27531.679688  27642.849609   \n",
            "2019-01-28  27576.960938  27531.679688  27642.849609  27942.470703   \n",
            "2019-01-29  27531.679688  27642.849609  27942.470703  27930.740234   \n",
            "2019-01-30  27642.849609  27942.470703  27930.740234  27990.210938   \n",
            "2019-01-31  27942.470703  27930.740234  27990.210938  27946.320313   \n",
            "2019-02-01  27930.740234  27990.210938  27946.320313  28143.839844   \n",
            "2019-02-04  27990.210938  27946.320313  28143.839844  28171.330078   \n",
            "2019-02-08  27946.320313  28143.839844  28171.330078  28497.589844   \n",
            "\n",
            "                 close_4       close_5          sma5  up_trend  down_trend  \\\n",
            "Date                                                                         \n",
            "2018-12-21  25845.699219  25130.349609  25522.101953     False       False   \n",
            "2018-12-24  25130.349609  25064.359375  25404.697656      True       False   \n",
            "2018-12-27  25064.359375  25626.029297  25434.127344     False       False   \n",
            "2018-12-28  25626.029297  25835.699219  25500.427344     False       False   \n",
            "2018-12-31  25835.699219  25875.449219  25506.377344     False       False   \n",
            "2019-01-02  25875.449219  26462.320313  25772.771485     False       False   \n",
            "2019-01-03  26462.320313  26521.429688  26064.185547     False        True   \n",
            "2019-01-04  26521.429688  26667.269531  26272.433594     False       False   \n",
            "2019-01-07  26667.269531  26298.330078  26364.959766     False       False   \n",
            "2019-01-08  26298.330078  26830.289063  26555.927735     False       False   \n",
            "2019-01-09  26830.289063  26902.099609  26643.883594     False       False   \n",
            "2019-01-10  26902.099609  26755.630859  26690.723828     False       False   \n",
            "2019-01-11  26755.630859  27090.810547  26775.432031     False       False   \n",
            "2019-01-14  27090.810547  27196.539063  26955.073828     False        True   \n",
            "2019-01-15  27196.539063  27005.449219  26990.105859     False       False   \n",
            "2019-01-16  27005.449219  27008.199219  27011.325781     False       False   \n",
            "2019-01-17  27008.199219  27120.980469  27084.395703     False       False   \n",
            "2019-01-18  27120.980469  27569.189453  27180.071485     False       False   \n",
            "2019-01-21  27569.189453  27576.960938  27256.155860     False        True   \n",
            "2019-01-22  27576.960938  27531.679688  27361.401953     False       False   \n",
            "2019-01-23  27531.679688  27642.849609  27488.332031     False       False   \n",
            "2019-01-24  27642.849609  27942.470703  27652.630078     False        True   \n",
            "2019-01-25  27942.470703  27930.740234  27724.940234     False        True   \n",
            "2019-01-28  27930.740234  27990.210938  27807.590234     False       False   \n",
            "2019-01-29  27990.210938  27946.320313  27890.518359     False       False   \n",
            "2019-01-30  27946.320313  28143.839844  27990.716406     False        True   \n",
            "2019-01-31  28143.839844  28171.330078  28036.488281     False        True   \n",
            "2019-02-01  28171.330078  28497.589844  28149.858203     False        True   \n",
            "2019-02-04  28497.589844  28432.050781  28238.226172     False        True   \n",
            "2019-02-08  28432.050781  27900.839844  28229.130078     False       False   \n",
            "\n",
            "            test1  test2  test3  nextclose_price_trend  \n",
            "Date                                                    \n",
            "2018-12-21      0      0      0                      0  \n",
            "2018-12-24      0      1      0                      1  \n",
            "2018-12-27      0      0      0                      0  \n",
            "2018-12-28      0      0      0                      0  \n",
            "2018-12-31      0      0      0                      0  \n",
            "2019-01-02      0      0      0                      0  \n",
            "2019-01-03      0      0      2                      2  \n",
            "2019-01-04      0      0      0                      0  \n",
            "2019-01-07      0      0      0                      0  \n",
            "2019-01-08      0      0      0                      0  \n",
            "2019-01-09      0      0      0                      0  \n",
            "2019-01-10      0      0      0                      0  \n",
            "2019-01-11      0      0      0                      0  \n",
            "2019-01-14      0      0      2                      2  \n",
            "2019-01-15      0      0      0                      0  \n",
            "2019-01-16      0      0      0                      0  \n",
            "2019-01-17      0      0      0                      0  \n",
            "2019-01-18      0      0      0                      0  \n",
            "2019-01-21      0      0      2                      2  \n",
            "2019-01-22      0      0      0                      0  \n",
            "2019-01-23      0      0      0                      0  \n",
            "2019-01-24      0      0      2                      2  \n",
            "2019-01-25      0      0      2                      2  \n",
            "2019-01-28      0      0      0                      0  \n",
            "2019-01-29      0      0      0                      0  \n",
            "2019-01-30      0      0      2                      2  \n",
            "2019-01-31      0      0      2                      2  \n",
            "2019-02-01      0      0      2                      2  \n",
            "2019-02-04      0      0      2                      2  \n",
            "2019-02-08      0      0      0                      0  \n",
            "(7931,)\n",
            "(7931, 9)\n"
          ]
        }
      ],
      "source": [
        "############################### main program ###############################\n",
        "\n",
        "#########################\n",
        "# read data source files\n",
        "#########################\n",
        "# read HSI data source\n",
        "dataset = read_csv('data/HSI.csv',header=0,parse_dates=[0],date_parser=parser,index_col=0)\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "# read candlesticks patterns\n",
        "candlesticks = read_csv('data/candlesticks_patterns.csv',header=0,parse_dates=[0],date_parser=parser,index_col=0)\n",
        "\n",
        "# define outcomes dataframe\n",
        "outcomes = DataFrame(index=dataset.index)\n",
        "\n",
        "# features dataset\n",
        "#getCandleSticks(candlesticks)\n",
        "getRSIChange(dataset)\n",
        "#getCloseChange(dataset)\n",
        "# getRocOFCloseChange(dataset)\n",
        "getSMA(dataset)\n",
        "#getVolumnChange(dataset)\n",
        "getPrevCloseTrend(dataset)\n",
        "#encodingExmaple()\n",
        "\n",
        "# outcomes dataset\n",
        "createOutcomesDataframe(dataset)\n",
        "\n",
        "# visualize data\n",
        "#outcomes['close_1_CAT'] = pd.cut(outcomes['close_1'], 8)\n",
        "#showHistogram(outcomes['close_1'])\n",
        "\n",
        "# combine features dataset and outcomes dataset\n",
        "y = outcomes.nextclose_price_trend\n",
        "#X = dataset\n",
        "X = dataset[[\n",
        "  'Open','High','Low','Close','Adj Close','Volume',\n",
        "  'RSI_5day_vs_prevday','smaDiff_5_14','prevclose_price_trend'\n",
        "]].copy()\n",
        "Xy = X.join(y).dropna()\n",
        "y = Xy[y.name]\n",
        "X = Xy[X.columns]\n",
        "print(y.shape)\n",
        "print(X.shape)\n",
        "\n",
        "# print(Xy.head(20))\n",
        "\n",
        "# print(Xy.columns)\n",
        "\n",
        "# Visualize correslation between variables\n",
        "# Correction Matrix Plot\n",
        "# Convert the input into a 2D dictionary\n",
        "df_copy = Xy[[\n",
        "  'RSI_5day_vs_prevday','smaDiff_5_14','prevclose_price_trend','nextclose_price_trend'\n",
        "]].copy()\n",
        "df_copy2 = Xy[[\n",
        "  'Open','Close','High','Low','Volume'\n",
        "]].copy()\n",
        "#corr = df_copy2.corr(method='pearson')\n",
        "#print(corr)\n",
        "\n",
        "#####\n",
        "# Create the plot\n",
        "#####\n",
        "#plt.pcolormesh(df, edgecolors='black')\n",
        "#plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n",
        "#plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSAfXOexpCu5"
      },
      "outputs": [],
      "source": [
        "#########################\n",
        "# output to CSV and exit\n",
        "########################\n",
        "dataset = dataset.dropna()\n",
        "Xy.to_csv('data/preprocessed_features_2.csv')\n",
        "#sys.exit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKUYyc3Sr4YO"
      },
      "source": [
        "# **Part 3: Features Association**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QixyEpxXs2wj",
        "outputId": "59ca745d-1f53-44d4-a386-8f8d3e7ec542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: apyori in /usr/local/lib/python3.10/dist-packages (1.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install apyori"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0IzdfIer33J",
        "outputId": "deb93314-31d9-4b4a-bc3a-b6adc859def0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-66-7d898ccaaeec>:26: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  from pandas import datetime\n"
          ]
        }
      ],
      "source": [
        "#####################################################\n",
        "# Examine the association between features\n",
        "#\n",
        "# Formula to calculate number of association rules R\n",
        "# given number of items d:\n",
        "#    R = 3^d - 2^(d+1) +1\n",
        "#####################################################\n",
        "\n",
        "########################\n",
        "# --- Features: ---\n",
        "# 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'candlesticks',\n",
        "# 'RSI', 'RSI_PREV', 'RSI_PREV_CAT', 'RSI_AVG_5DAYS', 'RSI_AVG_5DAYS_CAT',\n",
        "# 'RSI_5day_vs_prevday', 'sma5', 'sma14', 'sma50', 'sma200',\n",
        "# 'smaDiff_5_14', 'smaDiff_5_50', 'smaDiff_5_200', 'smaDiff_14_50',\n",
        "# 'smaDiff_14_200', 'smaDiff_50_200', 'OBV', 'Volume_CHG',\n",
        "# 'volumn_quantile_range', 'volumn_quantile_label', 'price_trend'\n",
        "########################\n",
        "\n",
        "########################\n",
        "# Current dataset:\n",
        "#   from 2001-Aug to 2018-Oct\n",
        "#   ie. 206 months\n",
        "########################\n",
        "\n",
        "from pandas import read_csv\n",
        "from pandas import datetime\n",
        "from pandas import concat\n",
        "from pandas import DataFrame\n",
        "from apyori import apriori\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpk6j2WRr-Bc"
      },
      "outputs": [],
      "source": [
        "# parsing date\n",
        "def parser(x):\n",
        "  return datetime.strptime(x,'%Y-%m-%d')\n",
        "\n",
        "# Class labeling\n",
        "def labeling_candlesticks(val):\n",
        "  if (val == -3):\n",
        "    return 'candle_extremely_bearish'\n",
        "  elif (val == -2):\n",
        "    return 'candle_strongly_bearish'\n",
        "  elif (val == -1):\n",
        "    return 'candle_bearish'\n",
        "  elif (val == 0):\n",
        "    return 'candle_neutral'\n",
        "  elif (val == 1):\n",
        "    return 'candle_bullish'\n",
        "  elif (val == 2):\n",
        "    return 'candle_strongly_bullish'\n",
        "  elif (val == 3):\n",
        "    return 'candle_extremely_bullish'\n",
        "\n",
        "def labeling_rsi(val):\n",
        "  if (val == 0):\n",
        "    return 'rsi_down'\n",
        "  elif (val == 1):\n",
        "    return 'rsi_up'\n",
        "\n",
        "def labeling_close_change(val):\n",
        "  if (val == 0):\n",
        "    return 'closeChg_down'\n",
        "  elif (val == 1):\n",
        "    return 'closeChg_up'\n",
        "\n",
        "def labeling_roc_close_change(val):\n",
        "  if (val == -1):\n",
        "    return 'rocCloseChg_slowDown'\n",
        "  elif (val == 1):\n",
        "    return 'rocCloseChg_speedUp'\n",
        "\n",
        "def labeling_volume_change(val):\n",
        "  if (val < -1):\n",
        "    return 'v1'\n",
        "  elif (val >= -1 and val < 0):\n",
        "    return 'v2'\n",
        "  elif (val >= 0 and val < 1):\n",
        "    return 'v3'\n",
        "  elif (val >= 1 and val < 2):\n",
        "    return 'v4'\n",
        "  elif (val >= 2 and val < 3):\n",
        "    return 'v5'\n",
        "  elif (val >= 3 and val < 4):\n",
        "    return 'v6'\n",
        "  elif (val >= 4 and val < 5):\n",
        "    return 'v7'\n",
        "  elif (val >= 5 and val < 6):\n",
        "    return 'v8'\n",
        "  elif (val >= 7):\n",
        "    return 'v9'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Atbo_a3sGGd"
      },
      "outputs": [],
      "source": [
        "def showHistogram(data):\n",
        "  # show histogram of next day's closing change categories\n",
        "  # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
        "  # n, bins, patches = plt.hist(x=data, bins='auto', color='#0504aa', alpha=0.7, rwidth=0.85)\n",
        "  # plt.grid(axis='y', alpha=0.75)\n",
        "  # plt.xlabel('Value Range')\n",
        "  # plt.ylabel('Frequency')\n",
        "  # plt.title(\"Next day's closing change categories\")\n",
        "  # plt.text(23, 45, r'$\\mu=15, b=3$')\n",
        "  # maxfreq = n.max()\n",
        "  # # Set a clean upper y-axis limit.\n",
        "  # plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
        "  data.plot.hist(grid=True, bins=30, rwidth=0.9, color='#607c8e')\n",
        "  plt.title(\"Next day's closing change categories\")\n",
        "  plt.xlabel('Counts')\n",
        "  plt.ylabel('Value')\n",
        "  plt.grid(axis='y', alpha=0.75)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh0W78mZsIRw"
      },
      "outputs": [],
      "source": [
        "# read data file\n",
        "dataset = read_csv('data/preprocessed_features_2.csv',header=0,parse_dates=[0],date_parser=parser,index_col=0)\n",
        "#print(dataset.columns)\n",
        "#print(dataset.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h5oBt5tsKmf",
        "outputId": "acb72f6b-90a7-4ce8-8fd4-3ba24cda1907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7931, 4)\n"
          ]
        }
      ],
      "source": [
        "# re-labeling of data value\n",
        "df = dataset[[\n",
        "  'RSI_5day_vs_prevday','smaDiff_5_14','prevclose_price_trend','nextclose_price_trend'\n",
        "]].copy()\n",
        "#df['candlesticks'] = df['candlesticks'].apply(lambda v: labeling_candlesticks(v))\n",
        "#df['RSI_CHG_CAT'] = df['RSI_CHG_CAT'].apply(lambda v: labeling_rsi(v))\n",
        "#df['rocOFCloseChangeCat'] = df['rocOFCloseChangeCat'].apply(lambda v: labeling_roc_close_change(v))\n",
        "#df['RSI_CHG_ROC_CAT'] = pd.cut(df['RSI_CHG_ROC'].replace(np.inf, np.nan).dropna(), 10)\n",
        "#df['Volume_CHG'] = df['Volume_CHG'].apply(lambda v: labeling_volume_change(v))\n",
        "#df['CLOSE_CHG_CAT'] = df['CLOSE_CHG_CAT'].apply(lambda v: labeling_close_change(v))\n",
        "#df['close_1_CAT'] = df['close_1_CAT'].apply(lambda v: 'close_up' if (v==1) else 'close_down')\n",
        "\n",
        "#print(df.head(20))\n",
        "#print(df.tail(20))\n",
        "\n",
        "print(df.shape)\n",
        "#print(df.values)\n",
        "\n",
        "# find and apply association rules\n",
        "rowCount = df.shape[0]  # number of rows\n",
        "itemCount = df.shape[1] # number of items\n",
        "\n",
        "records = []\n",
        "for i in range(0, rowCount):\n",
        "    records.append([str(df.values[i,j]) for j in range(0, itemCount)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iieLhJMPsUt8"
      },
      "outputs": [],
      "source": [
        "min_support_setting = 0.0002\n",
        "min_confidence_setting = 0.5\n",
        "min_lift_setting = 1.0\n",
        "min_length_setting = 2\n",
        "\n",
        "association_rules = list(apriori(records, min_support=min_support_setting, min_confidence=min_confidence_setting, min_lift=min_lift_setting, min_length=min_length_setting))\n",
        "association_results = list(association_rules)\n",
        "\n",
        "#print(\"Count of association rules: \", len(association_rules))\n",
        "#print(association_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKDnrtlJsXjv"
      },
      "outputs": [],
      "source": [
        "#####################\n",
        "# Write to CSV file\n",
        "#####################\n",
        "# candlesticks\n",
        "candlesticks_set = {\n",
        "  \"candle_extremely_bearish\",\n",
        "  \"candle_strongly_bearish\",\n",
        "  \"candle_bearish\",\n",
        "  \"candle_neutral\",\n",
        "  \"candle_bullish\",\n",
        "  \"candle_strongly_bullish\",\n",
        "  \"candle_extremely_bullish\"\n",
        "}\n",
        "\n",
        "# RSI\n",
        "rsi_set = {\n",
        "  \"noChange_below30\",\n",
        "  \"noChange_btw30and70\",\n",
        "  \"noChange_above70\",\n",
        "  \"below30_to_btw30and70\",\n",
        "  \"btw30and70_to_above70\",\n",
        "  \"above70_to_btw30and70\",\n",
        "  \"btw30and70_to_below30\",\n",
        "  \"below30_to_above70\",\n",
        "  \"above70_to_below30\"\n",
        "}\n",
        "\n",
        "# SMA\n",
        "sma_set = {\n",
        "  \"sma5_cross_above_sma14\",\n",
        "  \"sma5_cross_below_sma14\",\n",
        "  \"sma5_below_sma14\",\n",
        "  \"sma5_above_sma14\"\n",
        "}\n",
        "\n",
        "# volume\n",
        "volume_set = {\n",
        "  \"vol_up_trend\",\n",
        "  \"vol_down_trend\",\n",
        "  \"vol_normal\"\n",
        "}\n",
        "\n",
        "# previous 3 days close price trend\n",
        "prevclose_price_trend_set = {\n",
        "  \"prevclose_up_trend\",\n",
        "  \"prevclose_down_trend\",\n",
        "  \"prevclose_na\"\n",
        "}\n",
        "\n",
        "# next 3 days close price trend\n",
        "nextclose_price_trend_set = {\n",
        "  \"nextclose_up_trend\",\n",
        "  \"nextclose_down_trend\",\n",
        "  \"nextclose_na\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwTbjRbUsdhS",
        "outputId": "ea66a77d-dc36-4113-bbfe-d1096b39bcaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "113"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file = open(\"data/association_rules_001.csv\",\"w\")\n",
        "\n",
        "file.write(\"min_support,min_confidence,min_lift,RSI_5day_vs_prevday,smaDiff_5_14,prevclose_price_trend,nextclose_price_trend\" + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Byr3DkkushR7"
      },
      "outputs": [],
      "source": [
        "for item in association_rules:\n",
        "  #print(item[0]) # forzenset of items\n",
        "  for element in item[2]:  # item[2] is ordered_statistics\n",
        "    if (len(element[0]) > 0 and ('nextclose_up_trend' in element[1] or 'nextclose_down_trend' in element[1])):\n",
        "      value1 = 'null'\n",
        "      value2 = 'null'\n",
        "      value3 = 'null'\n",
        "      value4 = 'null'\n",
        "\n",
        "      fs1 = element[0]\n",
        "      for x in fs1:\n",
        "        if (x in rsi_set):\n",
        "          value1 = x\n",
        "        elif (x in sma_set):\n",
        "          value2 = x\n",
        "        elif (x in prevclose_price_trend_set):\n",
        "          value3 = x\n",
        "\n",
        "      fs2 = element[1]\n",
        "      for y in fs2:\n",
        "        if (y in nextclose_price_trend_set):\n",
        "          value4 = y\n",
        "\n",
        "      file.write(str(item[1]) + \",\" +\n",
        "                 str(element[2]) + \",\" +\n",
        "                 str(element[3]) + \",\" +\n",
        "                 value1 + \",\" +\n",
        "                 value2 + \",\" +\n",
        "                 value3 + \",\" +\n",
        "                 value4 + \",\" + \"\\n\")\n",
        "\n",
        "file.close()\n",
        "\n",
        "#sys.exit()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
